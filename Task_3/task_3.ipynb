{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa90994b-a19f-4cd6-9932-52664c4de4d0",
   "metadata": {},
   "source": [
    "# Task 3 Disease Prediction System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8e473-351f-4258-a9a1-c7619df65d27",
   "metadata": {},
   "source": [
    "### Problem Definition\n",
    "In modern healthcare, early and accurate disease identification is essential for effective treatment and resource optimization. With the exponential growth of medical data and patient records, data-driven approaches have become instrumental in supporting clinical decision-making. Machine learning algorithms enable the extraction of meaningful patterns from large-scale medical datasets, allowing for the development of intelligent systems that assist doctors in diagnosing diseases based on patient symptoms.\n",
    "\n",
    "The objective of this project is to design and implement a multi-symptom disease prediction system that can predict possible diseases based on a patient’s reported symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a55336-cc81-4985-b17b-e3527f786db7",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc9a746e-d183-4c5c-b04f-b07d428af9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    top_k_accuracy_score,\n",
    "    make_scorer\n",
    ")\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a88daca2-ee19-4888-a4a0-1374eacc78a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4920, 18)\n",
      "Number of samples: 4920\n",
      "Number of columns: 18\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/kendr/Downloads/archive/dataset.csv\")\n",
    "\n",
    "# Dataset Overview\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cf24592-d32e-4c54-9de9-9d7eb274a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symptoms per disease statistics:\n",
      "count    4920.000000\n",
      "mean        7.448780\n",
      "std         3.592166\n",
      "min         3.000000\n",
      "25%         5.000000\n",
      "50%         6.000000\n",
      "75%        10.000000\n",
      "max        17.000000\n",
      "Name: Symptom_Count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Symptom Analysis\n",
    "symptom_cols = [col for col in df.columns if col.startswith('Symptom_')]\n",
    "\n",
    "# Count non-null symptoms per disease (row-wise)\n",
    "df['Symptom_Count'] = df[symptom_cols].notna().sum(axis=1)\n",
    "\n",
    "print(\"Symptoms per disease statistics:\")\n",
    "print(df['Symptom_Count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "127a4560-8b56-4ca1-8baf-e956fe22052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symptoms in dataset: 131\n",
      "\n",
      "Top 20 most common symptoms:\n",
      "  fatigue: 1932\n",
      "  vomiting: 1914\n",
      "  high_fever: 1362\n",
      "  loss_of_appetite: 1152\n",
      "  nausea: 1146\n",
      "  headache: 1134\n",
      "  abdominal_pain: 1032\n",
      "  yellowish_skin: 912\n",
      "  yellowing_of_eyes: 816\n",
      "  chills: 798\n",
      "  skin_rash: 786\n",
      "  malaise: 702\n",
      "  chest_pain: 696\n",
      "  joint_pain: 684\n",
      "  itching: 678\n",
      "  sweating: 678\n",
      "  dark_urine: 570\n",
      "  cough: 564\n",
      "  diarrhoea: 564\n",
      "  irritability: 474\n"
     ]
    }
   ],
   "source": [
    "# Collect all symptoms\n",
    "all_symptoms = []\n",
    "for col in symptom_cols:\n",
    "    symptoms = df[col].dropna().astype(str).str.strip()\n",
    "    all_symptoms.extend(symptoms.tolist())\n",
    "\n",
    "# Filter out \"nan\" strings\n",
    "all_symptoms = [symptom for symptom in all_symptoms if symptom.lower() != 'nan']\n",
    "\n",
    "# Count symptom frequencies\n",
    "symptom_counter = Counter(all_symptoms)\n",
    "total_unique_symptoms = len(symptom_counter)\n",
    "\n",
    "print(f\"Total unique symptoms in dataset: {total_unique_symptoms}\")\n",
    "print(\"\\nTop 20 most common symptoms:\")\n",
    "for symptom, count in symptom_counter.most_common(20):\n",
    "    print(f\"  {symptom}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fb7f679-1052-436b-a3d5-a8e4eef2d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of symptoms appearing in multiple diseases: 51\n",
      "\n",
      "Top 10 symptoms by number of associated diseases:\n",
      "  vomiting: appears in 17 different diseases\n",
      "  fatigue: appears in 17 different diseases\n",
      "  high_fever: appears in 12 different diseases\n",
      "  headache: appears in 10 different diseases\n",
      "  loss_of_appetite: appears in 10 different diseases\n",
      "  nausea: appears in 10 different diseases\n",
      "  abdominal_pain: appears in 9 different diseases\n",
      "  yellowish_skin: appears in 8 different diseases\n",
      "  skin_rash: appears in 7 different diseases\n",
      "  chills: appears in 7 different diseases\n"
     ]
    }
   ],
   "source": [
    "# For each symptom, count how many different diseases it appears in\n",
    "symptom_disease_map = {}\n",
    "for symptom in symptom_counter.keys():\n",
    "    diseases_with_symptom = set()\n",
    "    for col in symptom_cols:\n",
    "        diseases = df[df[col].str.strip() == symptom]['Disease'].unique()\n",
    "        diseases_with_symptom.update(diseases)\n",
    "    symptom_disease_map[symptom] = len(diseases_with_symptom)\n",
    "\n",
    "# Find symptoms that appear in multiple diseases\n",
    "multi_disease_symptoms = {k: v for k, v in symptom_disease_map.items() if v > 1}\n",
    "print(f\"Number of symptoms appearing in multiple diseases: {len(multi_disease_symptoms)}\")\n",
    "\n",
    "# Top symptoms by disease diversity\n",
    "sorted_symptoms = sorted(symptom_disease_map.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 10 symptoms by number of associated diseases:\")\n",
    "for symptom, disease_count in sorted_symptoms[:10]:\n",
    "    print(f\"  {symptom}: appears in {disease_count} different diseases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6ecfb-c506-493f-bc3d-b0bb5200d33b",
   "metadata": {},
   "source": [
    "This dataset contains data on 41 distinct diseases, each characterized by combinations from 131 unique symptoms, with each disease entry averaging about 7.45 symptoms. Notably, 51 symptoms appear in multiple diseases, highlighting the complexity and overlap often encountered in clinical diagnosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fb090-9544-46e9-a239-58e91422ff9a",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Clean data\n",
    "- Feature engineering\n",
    "- Create feature matrix (X) and target labels (Y)\n",
    "- Train-test validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "056e7dee-aad6-45cb-b425-b5f26b6f1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned data:\n",
      "            Disease  Symptom_1             Symptom_2             Symptom_3\n",
      "0  Fungal infection    itching             skin_rash  nodal_skin_eruptions\n",
      "1  Fungal infection  skin_rash  nodal_skin_eruptions   dischromic _patches\n",
      "2  Fungal infection    itching  nodal_skin_eruptions   dischromic _patches\n",
      "3  Fungal infection    itching             skin_rash   dischromic _patches\n",
      "4  Fungal infection    itching             skin_rash  nodal_skin_eruptions\n",
      "\n",
      "'nan' strings remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "df_processed = df.copy()\n",
    "# Strip whitespace from all symptom entries (handle both string and empty)\n",
    "for col in symptom_cols:\n",
    "    df_processed[col] = df_processed[col].astype(str).str.strip()\n",
    "    # Replace 'nan' strings with empty strings\n",
    "    df_processed[col] = df_processed[col].replace('nan', '')\n",
    "\n",
    "# Strip whitespace from disease names\n",
    "df_processed['Disease'] = df_processed['Disease'].str.strip()\n",
    "\n",
    "print(f\"Sample cleaned data:\")\n",
    "print(df_processed[['Disease'] + symptom_cols[:3]].head())\n",
    "\n",
    "# Verify no 'nan' strings remain\n",
    "nan_strings = (df_processed[symptom_cols] == 'nan').sum().sum()\n",
    "print(f\"\\n'nan' strings remaining: {nan_strings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f1ba2c9-3c6a-4588-923f-26f8603ddae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 symptoms in vocabulary: ['abdominal_pain', 'abnormal_menstruation', 'acidity', 'acute_liver_failure', 'altered_sensorium', 'anxiety', 'back_pain', 'belly_pain', 'blackheads', 'bladder_discomfort']\n"
     ]
    }
   ],
   "source": [
    "# Collect all unique symptoms\n",
    "all_symptoms = set()\n",
    "for col in symptom_cols:\n",
    "    symptoms = df_processed[col][df_processed[col] != ''].unique()\n",
    "    all_symptoms.update(symptoms)\n",
    "\n",
    "# Convert to sorted list for consistent indexing\n",
    "symptom_list = sorted(list(all_symptoms))\n",
    "symptom_to_index = {symptom: idx for idx, symptom in enumerate(symptom_list)}\n",
    "\n",
    "print(f\"First 10 symptoms in vocabulary: {symptom_list[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05274b45-adb1-433f-8baa-eb617600a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_hot_encoding(row, symptom_to_index, symptom_cols):\n",
    "    \"\"\"\n",
    "    Create a multi-hot encoded vector for a disease entry.\n",
    "    Each symptom present is marked as 1, absent as 0.\n",
    "    \"\"\"\n",
    "    encoding = np.zeros(len(symptom_to_index))\n",
    "    \n",
    "    for col in symptom_cols:\n",
    "        symptom = row[col]\n",
    "        if symptom != '' and symptom in symptom_to_index:\n",
    "            encoding[symptom_to_index[symptom]] = 1\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "954b5a75-b987-44e0-b413-8b73d472becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (4920, 131)\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "X = np.array([create_multi_hot_encoding(row, symptom_to_index, symptom_cols) \n",
    "              for _, row in df_processed.iterrows()])\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "018d4b2a-5ad6-4692-a297-623d34a2c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease classes (first 10): ['(vertigo) Paroymsal  Positional Vertigo', 'AIDS', 'Acne', 'Alcoholic hepatitis', 'Allergy', 'Arthritis', 'Bronchial Asthma', 'Cervical spondylosis', 'Chicken pox', 'Chronic cholestasis']\n",
      "\n",
      "Disease mapping:\n",
      "  0: (vertigo) Paroymsal  Positional Vertigo\n",
      "  1: AIDS\n",
      "  2: Acne\n",
      "  3: Alcoholic hepatitis\n",
      "  4: Allergy\n",
      "  5: Arthritis\n",
      "  6: Bronchial Asthma\n",
      "  7: Cervical spondylosis\n",
      "  8: Chicken pox\n",
      "  9: Chronic cholestasis\n"
     ]
    }
   ],
   "source": [
    "# Encode disease labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_processed['Disease'])\n",
    "\n",
    "print(f\"Disease classes (first 10): {list(label_encoder.classes_[:10])}\")\n",
    "\n",
    "# Create disease mapping for reference\n",
    "disease_mapping = {idx: disease for idx, disease in enumerate(label_encoder.classes_)}\n",
    "reverse_disease_mapping = {disease: idx for idx, disease in enumerate(label_encoder.classes_)}\n",
    "\n",
    "print(f\"\\nDisease mapping:\")\n",
    "for i in range(min(10, len(disease_mapping))):\n",
    "    print(f\"  {i}: {disease_mapping[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45194c35-73a2-4abb-b2e2-51d614b8887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3936 samples (80.0%)\n",
      "Validation set size: 984 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "# Split data - 80% train, 20% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5289380-0b2a-4b12-98ac-f62be0752a19",
   "metadata": {},
   "source": [
    "### Base Model Construction\n",
    "- Build baseline AdaBoost with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f44fb2-dd80-4377-a2df-93f7a810d948",
   "metadata": {},
   "source": [
    "#### Why AdaBoost?\n",
    "In many real-world scenarios, patients exhibit overlapping or ambiguous symptoms, making traditional rule-based diagnostic systems insufficient. To address this, we aim to build an interpretable and data-driven model using the AdaBoost classifier.\n",
    "\n",
    "Advantages of AdaBoost:\n",
    "1. An ensemble algorithm that builds a strong classifier by combining multiple weak learners, making it highly effective in improving prediction accuracy for complex multi-symptom diagnostic problems. AdaBoost adaptively focuses on ambiguous instances (in the healthcare datasets where symptoms overlap between diseases), helping the model to learn subtle distinctions and reduce misclassification rates.\n",
    "\n",
    "2. It is fast, scalable, and robust, making it suitable for real-time applications and large datasets found in clinical environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ffe0b3a-d1ee-4395-ae39-af6bc60b90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Baseline AdaBoost model\n",
    "base_adaboost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945013bc-7ada-4179-961f-e6e7b8ee8156",
   "metadata": {},
   "source": [
    "### Model Training & Evaluation\n",
    "- Train base model on training set\n",
    "- Evaluate on validation set using:\n",
    "    Accuracy, Precision, Recall, F1-score, Top-K accuracy\n",
    "- Analyze results and error patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "941070f6-68e2-468c-99d5-26f5d1872153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and measure time\n",
    "start_time = time.time()\n",
    "base_adaboost.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2be93f07-a7f5-4fff-ba85-97cc72d81254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training set\n",
    "y_train_pred = base_adaboost.predict(X_train)\n",
    "y_train_proba = base_adaboost.predict_proba(X_train)\n",
    "\n",
    "# Predictions on validation set\n",
    "start_time = time.time()\n",
    "y_val_pred = base_adaboost.predict(X_val)\n",
    "y_val_proba = base_adaboost.predict_proba(X_val)\n",
    "inference_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "337a20e5-7cff-4900-8273-3e43b1a7fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric               Training Set         Validation Set       Difference          \n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy               0.9652 (96.52%)     0.9563 (95.63%)     0.0089\n",
      "Precision              0.9845 (98.45%)     0.9843 (98.43%)     0.0001\n",
      "Recall                 0.9652 (96.52%)     0.9563 (95.63%)     0.0089\n",
      "F1-Score               0.9708 (97.08%)     0.9644 (96.44%)     0.0064\n"
     ]
    }
   ],
   "source": [
    "# Training set metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Validation set metrics\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_precision = precision_score(y_val, y_val_pred, average='weighted', zero_division=0)\n",
    "val_recall = recall_score(y_val, y_val_pred, average='weighted', zero_division=0)\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"{'Metric':<20} {'Training Set':<20} {'Validation Set':<20} {'Difference':<20}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Accuracy':<20} {train_accuracy:>8.4f} ({train_accuracy*100:>5.2f}%)   {val_accuracy:>8.4f} ({val_accuracy*100:>5.2f}%)   {abs(train_accuracy-val_accuracy):>8.4f}\")\n",
    "print(f\"{'Precision':<20} {train_precision:>8.4f} ({train_precision*100:>5.2f}%)   {val_precision:>8.4f} ({val_precision*100:>5.2f}%)   {abs(train_precision-val_precision):>8.4f}\")\n",
    "print(f\"{'Recall':<20} {train_recall:>8.4f} ({train_recall*100:>5.2f}%)   {val_recall:>8.4f} ({val_recall*100:>5.2f}%)   {abs(train_recall-val_recall):>8.4f}\")\n",
    "print(f\"{'F1-Score':<20} {train_f1:>8.4f} ({train_f1*100:>5.2f}%)   {val_f1:>8.4f} ({val_f1*100:>5.2f}%)   {abs(train_f1-val_f1):>8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdd3ada2-f05f-40a9-9bab-7b2747bca9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Gap:        0.0089\n",
      "Model generalizes well (gap < 5%)\n"
     ]
    }
   ],
   "source": [
    "# Check for overfitting\n",
    "accuracy_gap = train_accuracy - val_accuracy\n",
    "\n",
    "print(f\"Accuracy Gap:        {accuracy_gap:.4f}\")\n",
    "\n",
    "if accuracy_gap < 0.05:\n",
    "    print(\"Model generalizes well (gap < 5%)\")\n",
    "elif accuracy_gap < 0.10:\n",
    "    print(\"Slight overfitting detected (gap 5-10%)\")\n",
    "else:\n",
    "    print(\"Significant overfitting (gap > 10%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02045ad3-4ca0-4e19-b762-66c79e075305",
   "metadata": {},
   "source": [
    "**Top-K accuracy analysis** is used to evaluate how often the true disease appears among the top K model predictions, rather than only considering when it is the top choice (Top-1 accuracy). This is especially important for real-world, multi-class diagnosis tasks, where several diseases can present with very similar symptoms. It reflects the reality that several plausible diagnoses may fit a patient’s symptoms, helping clinicians make safer, broader-informed decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07bb7a0d-6be0-4a51-8a79-672c896812a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K           Training Set              Validation Set            Improvement    \n",
      "--------------------------------------------------------------------------------\n",
      "Top-1             0.9652 (96.52%)        0.9563 (95.63%)      + 0.00%\n",
      "Top-2             0.9970 (99.70%)        0.9939 (99.39%)      + 3.76%\n",
      "Top-3             0.9990 (99.90%)        0.9980 (99.80%)      + 4.17%\n",
      "Top-5             1.0000 (100.00%)        1.0000 (100.00%)      + 4.37%\n"
     ]
    }
   ],
   "source": [
    "# Calculate Top-K accuracies for K = 1, 2, 3, 5\n",
    "k_values = [1, 2, 3, 5]\n",
    "topk_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Training set\n",
    "    train_topk = top_k_accuracy_score(y_train, y_train_proba, k=k, labels=np.arange(len(label_encoder.classes_)))\n",
    "    # Validation set\n",
    "    val_topk = top_k_accuracy_score(y_val, y_val_proba, k=k, labels=np.arange(len(label_encoder.classes_)))\n",
    "    topk_results.append({\n",
    "        'K': k,\n",
    "        'Train': train_topk,\n",
    "        'Validation': val_topk\n",
    "    })\n",
    "\n",
    "print(f\"{'Top-K':<15} {'Training Set':<25} {'Validation Set':<25} {'Improvement':<15}\")\n",
    "print(\"-\"*80)\n",
    "for result in topk_results:\n",
    "    k = result['K']\n",
    "    train_acc = result['Train']\n",
    "    val_acc = result['Validation']\n",
    "    improvement = val_acc - topk_results[0]['Validation']  # vs Top-1\n",
    "    \n",
    "    print(f\"{'Top-'+str(k):<15} {train_acc:>8.4f} ({train_acc*100:>5.2f}%)      {val_acc:>8.4f} ({val_acc*100:>5.2f}%)      +{improvement*100:>5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1a93702-0615-47d4-b86b-35106a4852e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 5 PERFORMING DISEASES (by F1-Score)\n",
      "Disease                                       Precision    Recall       F1-Score     Samples \n",
      "-----------------------------------------------------------------------------------------------\n",
      "AIDS                                            1.0000       1.0000       1.0000     24      \n",
      "Acne                                            1.0000       1.0000       1.0000     24      \n",
      "Arthritis                                       1.0000       1.0000       1.0000     24      \n",
      "Common Cold                                     1.0000       1.0000       1.0000     24      \n",
      "Dengue                                          1.0000       1.0000       1.0000     24      \n",
      "\n",
      "BOTTOM 5 PERFORMING DISEASES\n",
      "Disease                                       Precision    Recall       F1-Score     Samples \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Fungal infection                                1.0000       0.7917       0.8837     24      \n",
      "Gastroenteritis                                 1.0000       0.7917       0.8837     24      \n",
      "Alcoholic hepatitis                             1.0000       0.7083       0.8293     24      \n",
      "Typhoid                                         1.0000       0.7083       0.8293     24      \n",
      "Chronic cholestasis                             0.3582       1.0000       0.5275     24      \n",
      "\n",
      "24/41 diseases achieved perfect F1-score (100%)\n"
     ]
    }
   ],
   "source": [
    "# Get detailed classification report\n",
    "class_report = classification_report(\n",
    "    y_val, \n",
    "    y_val_pred, \n",
    "    target_names=label_encoder.classes_,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Extract per-class metrics\n",
    "class_performance = []\n",
    "for disease, metrics in class_report.items():\n",
    "    if disease not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        class_performance.append({\n",
    "            'Disease': disease,\n",
    "            'Precision': metrics['precision'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'F1-Score': metrics['f1-score'],\n",
    "            'Support': int(metrics['support'])\n",
    "        })\n",
    "\n",
    "# Sort by F1-score\n",
    "class_performance.sort(key=lambda x: x['F1-Score'], reverse=True)\n",
    "\n",
    "# Display top performers\n",
    "print(\"TOP 5 PERFORMING DISEASES (by F1-Score)\")\n",
    "print(f\"{'Disease':<45} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Samples':<8}\")\n",
    "print(\"-\"*95)\n",
    "for i, perf in enumerate(class_performance[:5], 1):\n",
    "    print(f\"{perf['Disease']:<45} {perf['Precision']:>8.4f}     {perf['Recall']:>8.4f}     {perf['F1-Score']:>8.4f}     {perf['Support']:<8}\")\n",
    "\n",
    "# Display bottom performers\n",
    "print(\"\\nBOTTOM 5 PERFORMING DISEASES\")\n",
    "print(f\"{'Disease':<45} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Samples':<8}\")\n",
    "print(\"-\"*95)\n",
    "for perf in class_performance[-5:]:\n",
    "    print(f\"{perf['Disease']:<45} {perf['Precision']:>8.4f}     {perf['Recall']:>8.4f}     {perf['F1-Score']:>8.4f}     {perf['Support']:<8}\")\n",
    "\n",
    "# Count perfect predictions\n",
    "perfect_diseases = sum(1 for p in class_performance if p['F1-Score'] == 1.0)\n",
    "print(f\"\\n{perfect_diseases}/{len(class_performance)} diseases achieved perfect F1-score (100%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41835f18-5a50-48d5-bc1b-b949f33fb063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Statistics:\n",
      "  • Total Predictions: 984\n",
      "  • Correct Predictions: 941 (95.63%)\n",
      "  • Misclassifications: 43 (4.37%)\n",
      "\n",
      "DISEASES WITH MOST MISCLASSIFICATIONS\n",
      "Disease                                       False Neg    False Pos    Total     \n",
      "--------------------------------------------------------------------------------\n",
      "Chronic cholestasis                           0            43           43        \n",
      "Alcoholic hepatitis                           7            0            7         \n",
      "Typhoid                                       7            0            7         \n",
      "Fungal infection                              5            0            5         \n",
      "Gastroenteritis                               5            0            5         \n",
      "Allergy                                       3            0            3         \n",
      "Bronchial Asthma                              3            0            3         \n",
      "Cervical spondylosis                          3            0            3         \n",
      "Hepatitis C                                   2            0            2         \n",
      "(vertigo) Paroymsal  Positional Vertigo       1            0            1         \n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Calculate key metrics from confusion matrix\n",
    "correct_predictions = np.trace(cm)\n",
    "total_predictions = np.sum(cm)\n",
    "misclassifications = total_predictions - correct_predictions\n",
    "\n",
    "print(f\"Overall Statistics:\")\n",
    "print(f\"  • Total Predictions: {total_predictions}\")\n",
    "print(f\"  • Correct Predictions: {correct_predictions} ({correct_predictions/total_predictions*100:.2f}%)\")\n",
    "print(f\"  • Misclassifications: {misclassifications} ({misclassifications/total_predictions*100:.2f}%)\")\n",
    "\n",
    "# Analyze which diseases are most problematic\n",
    "print(\"\\nDISEASES WITH MOST MISCLASSIFICATIONS\")\n",
    "disease_errors = []\n",
    "for i in range(len(cm)):\n",
    "    # Row sum minus diagonal = total errors for this disease (false negatives)\n",
    "    false_negatives = np.sum(cm[i, :]) - cm[i, i]\n",
    "    # Column sum minus diagonal = times other diseases were classified as this (false positives)\n",
    "    false_positives = np.sum(cm[:, i]) - cm[i, i]\n",
    "    total_errors = false_negatives + false_positives\n",
    "    \n",
    "    if total_errors > 0:\n",
    "        disease_errors.append({\n",
    "            'Disease': label_encoder.classes_[i],\n",
    "            'False_Negatives': false_negatives,\n",
    "            'False_Positives': false_positives,\n",
    "            'Total_Errors': total_errors\n",
    "        })\n",
    "\n",
    "disease_errors.sort(key=lambda x: x['Total_Errors'], reverse=True)\n",
    "\n",
    "print(f\"{'Disease':<45} {'False Neg':<12} {'False Pos':<12} {'Total':<10}\")\n",
    "print(\"-\"*80)\n",
    "for error in disease_errors[:10]:\n",
    "    print(f\"{error['Disease']:<45} {error['False_Negatives']:<12} {error['False_Positives']:<12} {error['Total_Errors']:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fda1e0e-6f6d-4083-bea7-f5127624adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Problematic Disease: Chronic cholestasis\n",
      "  • Total Errors: 43\n",
      "  • False Negatives: 0 (missed diagnoses)\n",
      "  • False Positives: 43 (over-diagnosed)\n"
     ]
    }
   ],
   "source": [
    "# Identify the most problematic disease\n",
    "most_confused = disease_errors[0] if disease_errors else None\n",
    "\n",
    "if most_confused:\n",
    "    problem_disease = most_confused['Disease']\n",
    "    problem_idx = np.where(label_encoder.classes_ == problem_disease)[0][0]\n",
    "    \n",
    "    print(f\"Most Problematic Disease: {problem_disease}\")\n",
    "    print(f\"  • Total Errors: {most_confused['Total_Errors']}\")\n",
    "    print(f\"  • False Negatives: {most_confused['False_Negatives']} (missed diagnoses)\")\n",
    "    print(f\"  • False Positives: {most_confused['False_Positives']} (over-diagnosed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cae88f76-7046-4aaa-9a21-f17a0c943849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Example 1: True Disease = Allergy\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Allergy                                         2.44%  ✓ CORRECT\n",
      "2      Chronic cholestasis                             2.44%  \n",
      "3      Hepatitis D                                     2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 2: True Disease = Varicose veins\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Varicose veins                                  2.44%  ✓ CORRECT\n",
      "2      Hepatitis D                                     2.44%  \n",
      "3      Chronic cholestasis                             2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 3: True Disease = Psoriasis\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Psoriasis                                       2.44%  ✓ CORRECT\n",
      "2      Hepatitis D                                     2.44%  \n",
      "3      Jaundice                                        2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 4: True Disease = Osteoarthristis\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Osteoarthristis                                 2.45%  ✓ CORRECT\n",
      "2      Chronic cholestasis                             2.44%  \n",
      "3      Hepatitis D                                     2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 5: True Disease = Hepatitis B\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Hepatitis B                                     2.44%  ✓ CORRECT\n",
      "2      Chronic cholestasis                             2.44%  \n",
      "3      Jaundice                                        2.44%  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample predictions\n",
    "# Select 5 random samples from validation set\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_val), size=5, replace=False)\n",
    "\n",
    "for idx, sample_idx in enumerate(sample_indices, 1):\n",
    "    true_label = y_val[sample_idx]\n",
    "    true_disease = label_encoder.classes_[true_label]\n",
    "    probabilities = y_val_proba[sample_idx]\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_k_indices = np.argsort(probabilities)[::-1][:3]\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Example {idx}: True Disease = {true_disease}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Rank':<6} {'Predicted Disease':<45} {'Probability':<15}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for rank, pred_idx in enumerate(top_k_indices, 1):\n",
    "        pred_disease = label_encoder.classes_[pred_idx]\n",
    "        probability = probabilities[pred_idx]\n",
    "        \n",
    "        # Mark if correct\n",
    "        marker = \"✓ CORRECT\" if pred_idx == true_label else \"\"\n",
    "        print(f\"{rank:<6} {pred_disease:<45} {probability*100:>6.2f}%  {marker}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f2d86-abd1-4509-8a25-e3bf65cff3b7",
   "metadata": {},
   "source": [
    "It was observed that the probabilities assigned to the top three predicted diseases are all very close, around 2.44% each. By printing the full probability distribution, we saw that the predicted “winning” class is only slightly higher than the others, making the difference nearly indistinguishable with just two decimal places. For this reason, we will display more decimal places for probabilities, allowing us to see even subtle differences in the model’s confidence for each disease prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0d05b39-ee13-4dc7-ab83-b4609ef2a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full probability distributions:\n",
      "Sample 0: Predicted class 23\n",
      "Probabilities: [0.02439298 0.02440716 0.02440701 0.02439564 0.02438462 0.02438616\n",
      " 0.02440088 0.02439907 0.024375   0.02442795 0.024375   0.024375\n",
      " 0.024375   0.024386   0.024375   0.02440518 0.02440177 0.02441363\n",
      " 0.02440209 0.024375   0.02440027 0.0244205  0.024375   0.0244414\n",
      " 0.024375   0.024375   0.024375   0.024375   0.0244011  0.024375\n",
      " 0.02440144 0.024375   0.02440177 0.02438737 0.024375   0.024375\n",
      " 0.024375   0.02439877 0.024375   0.024375   0.02438727]\n",
      "Max probability: 0.02444\n",
      "Top 3 classes: [23  9 21]\n",
      "--------------------------------------------------\n",
      "Sample 1: Predicted class 14\n",
      "Probabilities: [0.02439298 0.02440716 0.02440701 0.02439564 0.02438462 0.02438616\n",
      " 0.02440088 0.02438533 0.02438717 0.02439967 0.024375   0.024375\n",
      " 0.024375   0.024386   0.02445789 0.02440518 0.02438759 0.02441363\n",
      " 0.02438706 0.02438983 0.0244153  0.02440565 0.024375   0.02438747\n",
      " 0.024375   0.024375   0.024375   0.024375   0.02440242 0.024375\n",
      " 0.02440144 0.024375   0.02441551 0.02438737 0.024375   0.024375\n",
      " 0.024375   0.02439877 0.024375   0.024375   0.02438727]\n",
      "Max probability: 0.02446\n",
      "Top 3 classes: [14 32 20]\n",
      "--------------------------------------------------\n",
      "Sample 2: Predicted class 13\n",
      "Probabilities: [0.02439298 0.02440716 0.02439597 0.02439564 0.02438462 0.02438617\n",
      " 0.02440088 0.02438534 0.02438717 0.02441626 0.024375   0.024375\n",
      " 0.024375   0.0244212  0.024375   0.02440518 0.02440177 0.02441363\n",
      " 0.02439978 0.024375   0.0244153  0.0244205  0.024375   0.02440169\n",
      " 0.024375   0.024375   0.024375   0.024375   0.02441587 0.024375\n",
      " 0.02440144 0.024375   0.02441551 0.02438737 0.024375   0.024375\n",
      " 0.024375   0.02438629 0.024375   0.024375   0.02438728]\n",
      "Max probability: 0.02442\n",
      "Top 3 classes: [13 21  9]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the full probability distribution for first few samples\n",
    "print(\"Full probability distributions:\")\n",
    "for i in range(min(3, len(y_val_proba))):\n",
    "    print(f\"Sample {i}: Predicted class {y_val_pred[i]}\")\n",
    "    print(f\"Probabilities: {y_val_proba[i]}\")\n",
    "    print(f\"Max probability: {y_val_proba[i].max():.5f}\")\n",
    "    print(f\"Top 3 classes: {np.argsort(y_val_proba[i])[-3:][::-1]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d08db709-3165-40ef-bcf8-70be7ead0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Example 1: True Disease = Allergy\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Allergy                                       2.44499%  ✓ CORRECT\n",
      "2      Chronic cholestasis                           2.44279%  \n",
      "3      Hepatitis D                                   2.44205%  \n",
      "\n",
      "================================================================================\n",
      "Example 2: True Disease = Varicose veins\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Varicose veins                                2.44227%  ✓ CORRECT\n",
      "2      Hepatitis D                                   2.44205%  \n",
      "3      Chronic cholestasis                           2.44163%  \n",
      "\n",
      "================================================================================\n",
      "Example 3: True Disease = Psoriasis\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Psoriasis                                     2.44484%  ✓ CORRECT\n",
      "2      Hepatitis D                                   2.44205%  \n",
      "3      Jaundice                                      2.44159%  \n",
      "\n",
      "================================================================================\n",
      "Example 4: True Disease = Osteoarthristis\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Osteoarthristis                               2.44548%  ✓ CORRECT\n",
      "2      Chronic cholestasis                           2.44279%  \n",
      "3      Hepatitis D                                   2.44205%  \n",
      "\n",
      "================================================================================\n",
      "Example 5: True Disease = Hepatitis B\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Hepatitis B                                   2.44358%  ✓ CORRECT\n",
      "2      Chronic cholestasis                           2.44279%  \n",
      "3      Jaundice                                      2.44159%  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sample_idx in enumerate(sample_indices, 1):\n",
    "    true_label = y_val[sample_idx]\n",
    "    true_disease = label_encoder.classes_[true_label]\n",
    "    probabilities = y_val_proba[sample_idx]\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_k_indices = np.argsort(probabilities)[::-1][:3]\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Example {idx}: True Disease = {true_disease}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Rank':<6} {'Predicted Disease':<45} {'Probability':<15}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for rank, pred_idx in enumerate(top_k_indices, 1):\n",
    "        pred_disease = label_encoder.classes_[pred_idx]\n",
    "        probability = probabilities[pred_idx]\n",
    "        \n",
    "        # Mark if correct\n",
    "        marker = \"✓ CORRECT\" if pred_idx == true_label else \"\"\n",
    "        print(f\"{rank:<6} {pred_disease:<45} {probability*100:>6.5f}%  {marker}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44eff2a7-8ccf-4bda-b161-2819df0d66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy                : 0.9563 (95.63%)\n",
      "  Validation Precision               : 0.9843\n",
      "  Validation Recall                  : 0.9563\n",
      "  Validation F1-Score                : 0.9644\n",
      "  Top-3 Accuracy                     : 0.9980 (99.80%)\n",
      "  Top-5 Accuracy                     : 1.0000 (100.00%)\n",
      "  Perfect F1-Score Diseases          : 24/41\n",
      "  Total Misclassifications           : 43/984\n",
      "  Training Time                      : 0.94 seconds\n",
      "  Inference Time (per sample)        : 0.08 ms\n"
     ]
    }
   ],
   "source": [
    "summary_table = {\n",
    "    'Metric': [\n",
    "        'Validation Accuracy',\n",
    "        'Validation Precision',\n",
    "        'Validation Recall',\n",
    "        'Validation F1-Score',\n",
    "        'Top-3 Accuracy',\n",
    "        'Top-5 Accuracy',\n",
    "        'Perfect F1-Score Diseases',\n",
    "        'Total Misclassifications',\n",
    "        'Training Time',\n",
    "        'Inference Time (per sample)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{val_accuracy:.4f} ({val_accuracy*100:.2f}%)\",\n",
    "        f\"{val_precision:.4f}\",\n",
    "        f\"{val_recall:.4f}\",\n",
    "        f\"{val_f1:.4f}\",\n",
    "        f\"{topk_results[2]['Validation']:.4f} ({topk_results[2]['Validation']*100:.2f}%)\",\n",
    "        f\"{topk_results[3]['Validation']:.4f} ({topk_results[3]['Validation']*100:.2f}%)\",\n",
    "        f\"{perfect_diseases}/{len(class_performance)}\",\n",
    "        f\"{misclassifications}/{total_predictions}\",\n",
    "        f\"{training_time:.2f} seconds\",\n",
    "        f\"{(inference_time/len(X_val))*1000:.2f} ms\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for metric, value in zip(summary_table['Metric'], summary_table['Value']):\n",
    "    print(f\"  {metric:<35}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75bb10-7683-475f-8445-c0ad21c72c9b",
   "metadata": {},
   "source": [
    "The baseline AdaBoost classifier provided a strong foundation for multi-symptom disease prediction, achieving high accuracy (95.63%) and a strong F1-score (96.44%) on the validation set. The small gap between training and validation results confirms the model generalizes well without overfitting. Top-K analysis shows that the correct disease was present in the top-3 predictions for nearly every case, making this model highly reliable for generating ranked diagnostic suggestions.\n",
    "\n",
    "Performance was especially strong for most diseases, with 24 out of 41 reaching perfect F1-scores. However, misclassifications tended to cluster among certain diseases with overlapping symptom profiles, such as chronic cholestasis, highlighting areas for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9918b5-69a8-45f6-adb7-049218bc012c",
   "metadata": {},
   "source": [
    "### Test Set Construction with Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe17ca-9e73-4692-a707-b33ed269f621",
   "metadata": {},
   "source": [
    "In real-world medical diagnosis, symptoms often overlap across multiple diseases, and many patients present with combinations of symptoms. This complexity arises because:\n",
    "\n",
    "- Patients can have overlapping symptoms from two or more different conditions, which can lead to ambiguity or even multiple diagnoses at the same time.\n",
    "- Incomplete or missing symptom information is common in clinical settings—either because patients forget certain details, or early-stage diseases may not present with all expected symptoms.\n",
    "- Some symptoms are highly non-specific and can appear in many diseases, increasing the chances of diagnostic uncertainty and misclassification.\n",
    "\n",
    "To truly evaluate model robustness for real-world diagnosis, two distinct test set constructions are used:\n",
    "\n",
    "1. Blended disease samples test whether the model can handle diagnoses when symptoms from multiple conditions overlap, simulating complex cases where patients have co-occuring conditions or or display a mix of symptoms that could reasonably belong to more than one disease. \n",
    "2. Random noisy samples check the model’s ability to tolerate extra or missing symptoms. This reflects everyday situations where patient data is incomplete or they display mild symptoms unrelated to their main condition.\n",
    "\n",
    "Evaluating both aspects provides a comprehensive, realistic picture of how the model will perform in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "055b1800-8a00-497c-a985-94a58e9d3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease_symptoms(disease_name, df_processed, symptom_cols):\n",
    "    disease_data = df_processed[df_processed['Disease'] == disease_name]\n",
    "    symptoms = set()\n",
    "    for col in symptom_cols:\n",
    "        disease_symptoms = disease_data[col][disease_data[col] != ''].unique()\n",
    "        symptoms.update(disease_symptoms)\n",
    "    return list(symptoms)\n",
    "\n",
    "def create_blended_sample(diseases, symptom_counts, df_processed, symptom_cols):\n",
    "    blended_symptoms, symptom_sources, used_symptoms = [], [], set()\n",
    "    for disease, count in zip(diseases, symptom_counts):\n",
    "        available = [s for s in get_disease_symptoms(disease, df_processed, symptom_cols) if s not in used_symptoms]\n",
    "        if available:\n",
    "            n_to_select = min(count, len(available))\n",
    "            selected = np.random.choice(available, size=n_to_select, replace=False)\n",
    "            blended_symptoms.extend(selected)\n",
    "            symptom_sources.extend([disease] * n_to_select)\n",
    "            used_symptoms.update(selected)\n",
    "    return {\n",
    "        'symptoms': blended_symptoms,\n",
    "        'sources': symptom_sources,\n",
    "        'primary_disease': diseases[0],\n",
    "        'diseases': diseases,\n",
    "        'symptom_counts': symptom_counts,\n",
    "        'actual_counts': [symptom_sources.count(d) for d in diseases]\n",
    "    }\n",
    "\n",
    "def encode_symptom_list(symptom_list, symptom_to_index):\n",
    "    encoding = np.zeros(len(symptom_to_index))\n",
    "    for s in symptom_list:\n",
    "        if s in symptom_to_index:\n",
    "            encoding[symptom_to_index[s]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ef40dc3-704a-4d0b-86a5-49bb0413cdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controlled test samples: 50 (5 scenarios × 10)\n"
     ]
    }
   ],
   "source": [
    "# Controlled Test Set\n",
    "test_scenarios = [\n",
    "    {'name': 'Scenario 1: Pneumonia-dominant with Typhoid', 'diseases': ['Pneumonia', 'Typhoid'], 'symptom_counts': [8, 2], 'expected': 'Pneumonia'},\n",
    "    {'name': 'Scenario 2: Typhoid-dominant with Gastroenteritis', 'diseases': ['Typhoid', 'Gastroenteritis'], 'symptom_counts': [7, 3], 'expected': 'Typhoid'},\n",
    "    {'name': 'Scenario 3: Three-way blend (Pneumonia, Bronchial Asthma, Typhoid)', 'diseases': ['Pneumonia', 'Bronchial Asthma', 'Typhoid'], 'symptom_counts': [5, 3, 2], 'expected': 'Pneumonia'},\n",
    "    {'name': 'Scenario 4: Equal blend (Pneumonia, Typhoid)', 'diseases': ['Pneumonia', 'Typhoid'], 'symptom_counts': [5, 5], 'expected': 'Either Pneumonia or Typhoid'},\n",
    "    {'name': 'Scenario 5: Bronchial Asthma with minor Gastroenteritis', 'diseases': ['Bronchial Asthma', 'Gastroenteritis'], 'symptom_counts': [6, 2], 'expected': 'Bronchial Asthma'}\n",
    "]\n",
    "\n",
    "controlled_test_samples, controlled_test_labels, controlled_test_metadata = [], [], []\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    for _ in range(10):  # 10 samples per scenario\n",
    "        sample_data = create_blended_sample(scenario['diseases'], scenario['symptom_counts'], df_processed, symptom_cols)\n",
    "        if len(sample_data['symptoms']) >= 3:\n",
    "            encoded = encode_symptom_list(sample_data['symptoms'], symptom_to_index)\n",
    "            controlled_test_samples.append(encoded)\n",
    "            controlled_test_labels.append(reverse_disease_mapping[sample_data['primary_disease']])\n",
    "            controlled_test_metadata.append({\n",
    "                'scenario': scenario['name'],\n",
    "                'diseases': sample_data['diseases'],\n",
    "                'requested_counts': sample_data['symptom_counts'],\n",
    "                'actual_counts': sample_data['actual_counts'],\n",
    "                'symptoms': sample_data['symptoms'],\n",
    "                'sources': sample_data['sources'],\n",
    "                'expected': scenario['expected']\n",
    "            })\n",
    "\n",
    "X_test_controlled = np.array(controlled_test_samples)\n",
    "y_test_controlled = np.array(controlled_test_labels)\n",
    "\n",
    "print(f\"Controlled test samples: {len(X_test_controlled)} ({len(test_scenarios)} scenarios × 10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0add1f88-7eae-4185-be1a-b42fec605a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random noisy test samples: 200\n"
     ]
    }
   ],
   "source": [
    "# Noisy Test Set\n",
    "n_noisy_samples = 200\n",
    "noise_sample_indices = np.random.choice(len(X_val), size=n_noisy_samples, replace=False)\n",
    "X_test_noisy, y_test_noisy, noise_metadata = [], [], []\n",
    "\n",
    "for idx in noise_sample_indices:\n",
    "    original_sample, true_label = X_val[idx].copy(), y_val[idx]\n",
    "    orig_symptoms_idxs = np.where(original_sample == 1)[0]\n",
    "    orig_symptoms = [symptom_list[i] for i in orig_symptoms_idxs]\n",
    "    random_disease = np.random.choice(label_encoder.classes_)\n",
    "    while random_disease == label_encoder.classes_[true_label]:\n",
    "        random_disease = np.random.choice(label_encoder.classes_)\n",
    "    noise_symptoms = get_disease_symptoms(random_disease, df_processed, symptom_cols)\n",
    "    unique_noise_symptoms = [s for s in noise_symptoms if s not in set(orig_symptoms)]\n",
    "    if len(unique_noise_symptoms) > 0:\n",
    "        n_noise = np.random.randint(1, 4)\n",
    "        n_to_select = min(n_noise, len(unique_noise_symptoms))\n",
    "        selected_noise = np.random.choice(unique_noise_symptoms, size=n_to_select, replace=False)\n",
    "        noisy_sample = original_sample.copy()\n",
    "        for s in selected_noise:\n",
    "            if s in symptom_to_index:\n",
    "                noisy_sample[symptom_to_index[s]] = 1\n",
    "        X_test_noisy.append(noisy_sample)\n",
    "        y_test_noisy.append(true_label)\n",
    "        noise_metadata.append({\n",
    "            'original_disease': label_encoder.classes_[true_label],\n",
    "            'noise_disease': random_disease,\n",
    "            'n_original_symptoms': len(orig_symptoms),\n",
    "            'n_noise_symptoms': len(selected_noise),\n",
    "            'noise_level': len(selected_noise) / (len(orig_symptoms) + len(selected_noise)),\n",
    "            'original_symptoms': orig_symptoms,\n",
    "            'noise_symptoms': list(selected_noise)})\n",
    "\n",
    "X_test_noisy = np.array(X_test_noisy)\n",
    "y_test_noisy = np.array(y_test_noisy)\n",
    "print(f\"Random noisy test samples: {len(X_test_noisy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2574dc92-8a2b-45b2-8f42-4b075de66ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "def report_metrics(X_data, y_true, model, set_name):\n",
    "    y_pred = model.predict(X_data)\n",
    "    y_proba = model.predict_proba(X_data)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return acc, f1, y_pred, y_proba\n",
    "\n",
    "val_acc, val_f1, _, _ = report_metrics(X_val, y_val, base_adaboost, \"Validation\")\n",
    "controlled_acc, controlled_f1, y_controlled_pred, y_controlled_proba = report_metrics(X_test_controlled, y_test_controlled, base_adaboost, \"Controlled Blended\")\n",
    "noisy_acc, noisy_f1, y_noisy_pred, y_noisy_proba = report_metrics(X_test_noisy, y_test_noisy, base_adaboost, \"Random Noisy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bbaf4eb-f0e5-4116-9423-14fa06e4f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Controlled Blended Samples\n",
      "\n",
      "Scenario 1: Pneumonia-dominant with Typhoid\n",
      "  From Pneumonia:\n",
      "    1. chest_pain\n",
      "    2. fast_heart_rate\n",
      "    3. chills\n",
      "    4. phlegm\n",
      "    5. breathlessness\n",
      "    6. fatigue\n",
      "    7. rusty_sputum\n",
      "    8. malaise\n",
      "  From Typhoid:\n",
      "    1. abdominal_pain\n",
      "    2. diarrhoea\n",
      "\n",
      "Rank   Predicted Disease                        Probability     Status\n",
      "--------------------------------------------------------------------------------\n",
      "1      Pneumonia                                 2.44403%      ✓ PRIMARY DISEASE\n",
      "2      Chronic cholestasis                       2.44279%      \n",
      "3      Jaundice                                  2.44159%      \n",
      "4      Paralysis (brain hemorrhage)              2.44155%      \n",
      "5      Gastroenteritis                           2.44136%      \n",
      "\n",
      "Scenario 2: Typhoid-dominant with Gastroenteritis\n",
      "  From Typhoid:\n",
      "    1. constipation\n",
      "    2. chills\n",
      "    3. diarrhoea\n",
      "    4. headache\n",
      "    5. vomiting\n",
      "    6. toxic_look_(typhos)\n",
      "    7. fatigue\n",
      "  From Gastroenteritis:\n",
      "    1. sunken_eyes\n",
      "    2. dehydration\n",
      "\n",
      "Rank   Predicted Disease                        Probability     Status\n",
      "--------------------------------------------------------------------------------\n",
      "1      Gastroenteritis                           2.44382%      ○ BLENDED DISEASE\n",
      "2      Chronic cholestasis                       2.44279%      \n",
      "3      Typhoid                                   2.44226%      ✓ PRIMARY DISEASE\n",
      "4      Hepatitis D                               2.44205%      \n",
      "5      Jaundice                                  2.44159%      \n",
      "\n",
      "Scenario 3: Three-way blend (Pneumonia, Bronchial Asthma, Typhoid)\n",
      "  From Pneumonia:\n",
      "    1. breathlessness\n",
      "    2. phlegm\n",
      "    3. sweating\n",
      "    4. malaise\n",
      "    5. cough\n",
      "  From Bronchial Asthma:\n",
      "    1. mucoid_sputum\n",
      "    2. fatigue\n",
      "    3. high_fever\n",
      "  From Typhoid:\n",
      "    1. abdominal_pain\n",
      "    2. headache\n",
      "\n",
      "Rank   Predicted Disease                        Probability     Status\n",
      "--------------------------------------------------------------------------------\n",
      "1      Heart attack                              2.44322%      \n",
      "2      Chronic cholestasis                       2.44279%      \n",
      "3      Bronchial Asthma                          2.44246%      ○ BLENDED DISEASE\n",
      "4      Paralysis (brain hemorrhage)              2.44155%      \n",
      "5      Hepatitis C                               2.44153%      \n",
      "\n",
      "Scenario 4: Equal blend (Pneumonia, Typhoid)\n",
      "  From Pneumonia:\n",
      "    1. chest_pain\n",
      "    2. fast_heart_rate\n",
      "    3. malaise\n",
      "    4. cough\n",
      "    5. fatigue\n",
      "  From Typhoid:\n",
      "    1. constipation\n",
      "    2. diarrhoea\n",
      "    3. chills\n",
      "    4. vomiting\n",
      "    5. abdominal_pain\n",
      "\n",
      "Rank   Predicted Disease                        Probability     Status\n",
      "--------------------------------------------------------------------------------\n",
      "1      Chronic cholestasis                       2.44279%      \n",
      "2      Hepatitis D                               2.44205%      \n",
      "3      Jaundice                                  2.44159%      \n",
      "4      Paralysis (brain hemorrhage)              2.44155%      \n",
      "5      Heart attack                              2.44148%      \n",
      "\n",
      "Scenario 5: Bronchial Asthma with minor Gastroenteritis\n",
      "  From Bronchial Asthma:\n",
      "    1. family_history\n",
      "    2. cough\n",
      "    3. high_fever\n",
      "    4. breathlessness\n",
      "    5. mucoid_sputum\n",
      "    6. fatigue\n",
      "  From Gastroenteritis:\n",
      "    1. sunken_eyes\n",
      "    2. dehydration\n",
      "\n",
      "Rank   Predicted Disease                        Probability     Status\n",
      "--------------------------------------------------------------------------------\n",
      "1      Bronchial Asthma                          2.44536%      ✓ PRIMARY DISEASE\n",
      "2      Gastroenteritis                           2.44249%      ○ BLENDED DISEASE\n",
      "3      Heart attack                              2.44174%      \n",
      "4      Jaundice                                  2.44159%      \n",
      "5      Paralysis (brain hemorrhage)              2.44155%      \n"
     ]
    }
   ],
   "source": [
    "# Scenario Results\n",
    "print(\"1. Controlled Blended Samples\")\n",
    "for scenario in test_scenarios:\n",
    "    scenario_name = scenario['name']\n",
    "    scenario_samples = [i for i, meta in enumerate(controlled_test_metadata) if meta['scenario'] == scenario_name]\n",
    "    print(f\"\\n{scenario_name}\")\n",
    "    if scenario_samples:\n",
    "        sample_idx = scenario_samples[0]\n",
    "        m = controlled_test_metadata[sample_idx]\n",
    "        true_label = y_test_controlled[sample_idx]\n",
    "        true_disease = label_encoder.classes_[true_label]\n",
    "        proba = y_controlled_proba[sample_idx]\n",
    "        top_k_indices = np.argsort(proba)[::-1][:5]\n",
    "\n",
    "        symptom_by_source = {}\n",
    "        for sym, src in zip(m['symptoms'], m['sources']):\n",
    "            symptom_by_source.setdefault(src, []).append(sym)\n",
    "        for d in m['diseases']:\n",
    "            if d in symptom_by_source:\n",
    "                print(f\"  From {d}:\")\n",
    "                for i, s in enumerate(symptom_by_source[d], 1):\n",
    "                    print(f\"    {i}. {s}\")\n",
    "\n",
    "        print(f\"\\n{'Rank':<6} {'Predicted Disease':<40} {'Probability':<15} {'Status'}\")\n",
    "        print(\"-\"*80)\n",
    "        for rank, pred_idx in enumerate(top_k_indices, 1):\n",
    "            pred_dis = label_encoder.classes_[pred_idx]\n",
    "            prob = proba[pred_idx]\n",
    "            status = ''\n",
    "            if pred_dis == true_disease:\n",
    "                status = \"✓ PRIMARY DISEASE\"\n",
    "            elif pred_dis in m['diseases']:\n",
    "                status = \"○ BLENDED DISEASE\"\n",
    "            print(f\"{rank:<6} {pred_dis:<40} {prob*100:>8.5f}%      {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc372ecd-4d62-492d-ab44-7f44abf827f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Random Noisy Samples\n",
      "\n",
      "Example 1:\n",
      "  Original Disease: Pneumonia\n",
      "  Original Symptoms (10): breathlessness, chest_pain, cough, fast_heart_rate, fatigue...\n",
      "  Added Noise from AIDS (1): extra_marital_contacts\n",
      "  Noise Level: 9.1%\n",
      "  Predicted: Pneumonia ✓\n",
      "  Top prediction probability: 2.44403%\n",
      "\n",
      "Example 2:\n",
      "  Original Disease: Urinary tract infection\n",
      "  Original Symptoms (3): bladder_discomfort, burning_micturition, foul_smell_of urine...\n",
      "  Added Noise from Hypothyroidism (2): brittle_nails, fatigue\n",
      "  Noise Level: 40.0%\n",
      "  Predicted: Urinary tract infection ✓\n",
      "  Top prediction probability: 2.44295%\n",
      "\n",
      "Example 3:\n",
      "  Original Disease: Bronchial Asthma\n",
      "  Original Symptoms (5): breathlessness, family_history, fatigue, high_fever, mucoid_sputum...\n",
      "  Added Noise from Urinary tract infection (3): foul_smell_of urine, burning_micturition, bladder_discomfort\n",
      "  Noise Level: 37.5%\n",
      "  Predicted: Bronchial Asthma ✓\n",
      "  Top prediction probability: 2.44394%\n"
     ]
    }
   ],
   "source": [
    "# Noisy Samples\n",
    "print(\"2. Random Noisy Samples\")\n",
    "for i in range(min(3, len(noise_metadata))):\n",
    "    meta = noise_metadata[i]\n",
    "    true_label = y_test_noisy[i]\n",
    "    true_disease = label_encoder.classes_[true_label]\n",
    "    probabilities = y_noisy_proba[i]\n",
    "    pred_label = y_noisy_pred[i]\n",
    "    pred_disease = label_encoder.classes_[pred_label]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Original Disease: {meta['original_disease']}\")\n",
    "    print(f\"  Original Symptoms ({meta['n_original_symptoms']}): {', '.join(meta['original_symptoms'][:5])}...\")\n",
    "    print(f\"  Added Noise from {meta['noise_disease']} ({meta['n_noise_symptoms']}): {', '.join(meta['noise_symptoms'])}\")\n",
    "    print(f\"  Noise Level: {meta['noise_level']*100:.1f}%\")\n",
    "    print(f\"  Predicted: {pred_disease} {'✓' if pred_label == true_label else '✗'}\")\n",
    "    print(f\"  Top prediction probability: {probabilities[pred_label]*100:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "351bf899-3145-4b7e-889a-2408d795293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Type             Accuracy        F1-Score        Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Clean (Validation)          0.9563 (95.63%)    0.9644     Baseline\n",
      "1. Controlled Blended       0.3400 (34.00%)    0.3812     -61.63%\n",
      "2. Random Noisy             0.8800 (88.00%)    0.8905     -7.63%\n"
     ]
    }
   ],
   "source": [
    "# Metrics Summary\n",
    "print(f\"{'Test Set Type':<25} {'Accuracy':<15} {'F1-Score':<15} {'Performance'}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Clean (Validation)':<25} {val_acc:>8.4f} ({val_acc*100:>5.2f}%)  {val_f1:>8.4f}     Baseline\")\n",
    "print(f\"{'1. Controlled Blended':<25} {controlled_acc:>8.4f} ({controlled_acc*100:>5.2f}%)  {controlled_f1:>8.4f}     {(controlled_acc-val_acc)*100:>+5.2f}%\")\n",
    "print(f\"{'2. Random Noisy':<25} {noisy_acc:>8.4f} ({noisy_acc*100:>5.2f}%)  {noisy_f1:>8.4f}     {(noisy_acc-val_acc)*100:>+5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca193c26-3388-4fc4-beb8-9f6ef920be4d",
   "metadata": {},
   "source": [
    "The baseline AdaBoost model performed well with realistic noisy cases, reaching 86.50% accuracy, but struggled with controlled blended samples, where accuracy dropped to 36.00%. These results show the model is robust to random noise, but symptom blends from multiple diseases pose a significant challenge. Most primary diseases still ranked near the top, yet ambiguous cases highlight the need for more advanced or ensemble approaches in clinical prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbe7d5-c6fd-43ff-be1c-0dcec7f11513",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "- Define parameter grid\n",
    "- GridSearchCV with cross-validation \n",
    "- Compare CV scores across parameter combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded2a66-3c30-4f52-8199-617dcb8a2852",
   "metadata": {},
   "source": [
    "Objective: Optimize AdaBoost parameters to improve upon baseline performance\n",
    "\n",
    "Strategy:\n",
    "1. Define comprehensive parameter grid\n",
    "2. Use 5-fold cross-validation for robust evaluation\n",
    "3. Optimize for F1-score (balanced metric)\n",
    "4. Compare results with baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3852654a-c94a-4461-86ae-f1fda89a8187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Grid:\n",
      "--------------------------------------------------------------------------------\n",
      "  estimator__max_depth               : [4, 5, 6, 7]\n",
      "  estimator__min_samples_split       : [2, 5]\n",
      "  estimator__min_samples_leaf        : [1, 2, 4]\n",
      "  n_estimators                       : [75, 100, 150, 200]\n",
      "  learning_rate                      : [0.5, 0.8, 1.0]\n",
      "\n",
      "Total Combinations:                 288\n",
      "With 5-fold CV:                     1440 model fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    # Base estimator parameters (Decision Tree)\n",
    "    'estimator__max_depth': [4, 5, 6, 7],\n",
    "    'estimator__min_samples_split': [2, 5],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    \n",
    "    # AdaBoost parameters\n",
    "    'n_estimators': [75, 100, 150, 200],\n",
    "    'learning_rate': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(\"Parameter Grid:\")\n",
    "print(\"-\" * 80)\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param:<35}: {values}\")\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = 1\n",
    "for values in param_grid.values():\n",
    "    total_combinations *= len(values)\n",
    "\n",
    "print(f\"\\n{'Total Combinations:':<35} {total_combinations}\")\n",
    "print(f\"{'With 5-fold CV:':<35} {total_combinations * 5} model fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1821f56f-cb8f-4fd9-a515-91d4fd807e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Configuration:\n",
      "  • Cross-Validation: 5-fold\n",
      "  • Optimization Metric: F1-Score (weighted)\n",
      "  • Additional Metrics: Accuracy, F1-Macro\n",
      "  • Parallel Jobs: All available cores\n",
      "  • Total fits: 1440\n"
     ]
    }
   ],
   "source": [
    "# Create base estimator \n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted', zero_division=0),\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=scoring,\n",
    "    refit='f1_weighted',  # Optimize for weighted F1-score\n",
    "    n_jobs=-1,  \n",
    "    verbose=2,  \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"GridSearchCV Configuration:\")\n",
    "print(f\"  • Cross-Validation: 5-fold\")\n",
    "print(f\"  • Optimization Metric: F1-Score (weighted)\")\n",
    "print(f\"  • Additional Metrics: Accuracy, F1-Macro\")\n",
    "print(f\"  • Parallel Jobs: All available cores\")\n",
    "print(f\"  • Total fits: {total_combinations * 5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f73d8e7-0543-40da-9b1d-36cfd74f46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Grid Search Completed in 17.12 minutes\n"
     ]
    }
   ],
   "source": [
    "# Run grid search\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "print(f\"Grid Search Completed in {optimization_time/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d91e56b7-13af-424a-8d8c-ff983b63f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameters:\n",
      "\n",
      "Base Estimator (Decision Tree):\n",
      "  • max_depth:         6\n",
      "  • min_samples_split: 5\n",
      "  • min_samples_leaf:  1\n",
      "\n",
      "AdaBoost Parameters:\n",
      "  • n_estimators:      75\n",
      "  • learning_rate:     1.0\n",
      "\n",
      "Cross-Validation Performance:\n",
      "  • Best CV F1-Score:  1.0000 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Optimal Hyperparameters:\")\n",
    "print(\"\\nBase Estimator (Decision Tree):\")\n",
    "print(f\"  • max_depth:         {best_params['estimator__max_depth']}\")\n",
    "print(f\"  • min_samples_split: {best_params['estimator__min_samples_split']}\")\n",
    "print(f\"  • min_samples_leaf:  {best_params['estimator__min_samples_leaf']}\")\n",
    "\n",
    "print(\"\\nAdaBoost Parameters:\")\n",
    "print(f\"  • n_estimators:      {best_params['n_estimators']}\")\n",
    "print(f\"  • learning_rate:     {best_params['learning_rate']}\")\n",
    "\n",
    "print(\"\\nCross-Validation Performance:\")\n",
    "print(f\"  • Best CV F1-Score:  {best_score:.4f} ({best_score*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a16bbe0-6800-4451-bdd9-bd7b50add0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy         0.9652        1.0000        +0.0348\n",
      "Training F1-Score         0.9708        1.0000        +0.0292\n",
      "Validation Accuracy       0.9563        1.0000        +0.0437\n",
      "Validation F1-Score       0.9644        1.0000        +0.0356\n",
      "Overfitting Gap           0.0089        0.0000        -0.0089\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Optimized model improved validation accuracy by 4.37%\n"
     ]
    }
   ],
   "source": [
    "# Get best model from grid search\n",
    "optimized_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions with optimized model\n",
    "y_train_opt_pred = optimized_model.predict(X_train)\n",
    "y_val_opt_pred = optimized_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "train_opt_accuracy = accuracy_score(y_train, y_train_opt_pred)\n",
    "val_opt_accuracy = accuracy_score(y_val, y_val_opt_pred)\n",
    "train_opt_f1 = f1_score(y_train, y_train_opt_pred, average='weighted', zero_division=0)\n",
    "val_opt_f1 = f1_score(y_val, y_val_opt_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Training metrics\n",
    "print(f\"{'Training Accuracy':<25} {train_accuracy:.4f}        {train_opt_accuracy:.4f}        \"\n",
    "      f\"{(train_opt_accuracy - train_accuracy):+.4f}\")\n",
    "print(f\"{'Training F1-Score':<25} {train_f1:.4f}        {train_opt_f1:.4f}        \"\n",
    "      f\"{(train_opt_f1 - train_f1):+.4f}\")\n",
    "\n",
    "# Validation metrics\n",
    "print(f\"{'Validation Accuracy':<25} {val_accuracy:.4f}        {val_opt_accuracy:.4f}        \"\n",
    "      f\"{(val_opt_accuracy - val_accuracy):+.4f}\")\n",
    "print(f\"{'Validation F1-Score':<25} {val_f1:.4f}        {val_opt_f1:.4f}        \"\n",
    "      f\"{(val_opt_f1 - val_f1):+.4f}\")\n",
    "\n",
    "# Overfitting analysis\n",
    "baseline_gap = train_accuracy - val_accuracy\n",
    "optimized_gap = train_opt_accuracy - val_opt_accuracy\n",
    "\n",
    "print(f\"{'Overfitting Gap':<25} {baseline_gap:.4f}        {optimized_gap:.4f}        \"\n",
    "      f\"{(optimized_gap - baseline_gap):+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "# Determine improvement\n",
    "improvement_pct = (val_opt_accuracy - val_accuracy) * 100\n",
    "if improvement_pct > 0:\n",
    "    print(f\"✓ Optimized model improved validation accuracy by {improvement_pct:.2f}%\")\n",
    "elif improvement_pct == 0:\n",
    "    print(f\"→ Optimized model maintains baseline performance\")\n",
    "else:\n",
    "    print(f\"⚠ Optimized model decreased by {abs(improvement_pct):.2f}% \"\n",
    "          f\"(may indicate overfitting to CV folds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c61e8e77-88ff-4a1b-89e7-a8fd1d880410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K Accuracy Comparison:\n",
      "--------------------------------------------------------------------------------\n",
      "K          Baseline        Optimized       Improvement    \n",
      "--------------------------------------------------------------------------------\n",
      "Top-1      0.9563        1.0000        +0.0437 (+4.37%)\n",
      "Top-2      0.9939        1.0000        +0.0061 (+0.61%)\n",
      "Top-3      0.9980        1.0000        +0.0020 (+0.20%)\n",
      "Top-5      1.0000        1.0000        +0.0000 (+0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Get probabilities from optimized model\n",
    "y_val_opt_proba = optimized_model.predict_proba(X_val)\n",
    "\n",
    "k_values = [1, 2, 3, 5]\n",
    "topk_optimized = []\n",
    "\n",
    "for k in k_values:\n",
    "    topk_acc = top_k_accuracy_score(y_val, y_val_opt_proba, k=k, \n",
    "                                     labels=np.arange(len(label_encoder.classes_)))\n",
    "    topk_optimized.append(topk_acc)\n",
    "\n",
    "print(\"Top-K Accuracy Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'K':<10} {'Baseline':<15} {'Optimized':<15} {'Improvement':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for k, baseline_result, opt_acc in zip(k_values, topk_results, topk_optimized):\n",
    "    baseline_acc = baseline_result['Validation']\n",
    "    improvement = opt_acc - baseline_acc\n",
    "    print(f\"{'Top-'+str(k):<10} {baseline_acc:.4f}        {opt_acc:.4f}        \"\n",
    "          f\"{improvement:+.4f} ({improvement*100:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9520003-3614-43f6-bf51-b91af93554e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Model Configuration:\n",
      "--------------------------------------------------------------------------------\n",
      "model_name: Optimized AdaBoost Classifier\n",
      "base_estimator: Decision Tree\n",
      "hyperparameters:\n",
      "  estimator__max_depth: 6\n",
      "  estimator__min_samples_leaf: 1\n",
      "  estimator__min_samples_split: 5\n",
      "  learning_rate: 1.0\n",
      "  n_estimators: 75\n",
      "cv_f1_score: 1.0000\n",
      "validation_accuracy: 1.0000\n",
      "validation_f1_score: 1.0000\n",
      "training_time: 1027.48 seconds\n",
      "improvement_over_baseline: 0.0437\n"
     ]
    }
   ],
   "source": [
    "optimized_config = {\n",
    "    'model_name': 'Optimized AdaBoost Classifier',\n",
    "    'base_estimator': 'Decision Tree',\n",
    "    'hyperparameters': best_params,\n",
    "    'cv_f1_score': best_score,\n",
    "    'validation_accuracy': val_opt_accuracy,\n",
    "    'validation_f1_score': val_opt_f1,\n",
    "    'training_time': optimization_time,\n",
    "    'improvement_over_baseline': val_opt_accuracy - val_accuracy\n",
    "}\n",
    "\n",
    "print(\"Optimized Model Configuration:\")\n",
    "print(\"-\" * 80)\n",
    "for key, value in optimized_config.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    elif isinstance(value, float):\n",
    "        if 'time' in key.lower():\n",
    "            print(f\"{key}: {value:.2f} seconds\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c635e2-b6b0-4f5b-a1f2-2532b6f27fad",
   "metadata": {},
   "source": [
    "### Final Model Evaluation\n",
    "- Retrain with best hyperparameters on full training set\n",
    "- Compare baseline and optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85077178-151b-4869-8db2-87d9d92b0f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Test Set             Model        Samples    Accuracy     F1-Score     Top-3      Top-5      Errors  \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Clean Validation     Baseline     984        0.9563       0.9644       0.9980    1.0000    43      \n",
      "Random Noisy         Baseline     200        0.8800       0.8905       0.9800    0.9950    24      \n",
      "Blended Controlled   Baseline     50         0.3400       0.3812       0.6400    0.6600    33      \n",
      "Clean Validation     Optimized    984        1.0000       1.0000       1.0000    1.0000    0       \n",
      "Random Noisy         Optimized    200        0.9600       0.9601       1.0000    1.0000    8       \n",
      "Blended Controlled   Optimized    50         0.4200       0.4687       0.6800    0.8000    29      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Accuracy drop from clean to noisy: 4.00%\n",
      "F1-score drop from clean to noisy: 3.99%\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_pred, y_proba, label_encoder):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        'top3': top_k_accuracy_score(y_true, y_proba, k=3, labels=np.arange(len(label_encoder.classes_))),\n",
    "        'top5': top_k_accuracy_score(y_true, y_proba, k=5, labels=np.arange(len(label_encoder.classes_))),\n",
    "        'errors': np.sum(y_true != y_pred)\n",
    "    }\n",
    "\n",
    "sets_and_models = [\n",
    "    (\"Clean Validation\", y_val, X_val, base_adaboost),\n",
    "    (\"Random Noisy\", y_test_noisy, X_test_noisy, base_adaboost),\n",
    "    (\"Blended Controlled\", y_test_controlled, X_test_controlled, base_adaboost),\n",
    "    (\"Clean Validation\", y_val, X_val, optimized_model),\n",
    "    (\"Random Noisy\", y_test_noisy, X_test_noisy, optimized_model),\n",
    "    (\"Blended Controlled\", y_test_controlled, X_test_controlled, optimized_model),\n",
    "]\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for name, y_true, X, model in sets_and_models:\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)\n",
    "    metrics = compute_metrics(y_true, y_pred, y_proba, label_encoder)\n",
    "    model_type = \"Optimized\" if model is optimized_model else \"Baseline\"\n",
    "    comparison_data.append({\n",
    "        'Test Set': name,\n",
    "        'Samples': len(y_true),\n",
    "        'Model': model_type,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'F1-Score': metrics['f1'],\n",
    "        'Top-3 Acc': metrics['top3'],\n",
    "        'Top-5 Acc': metrics['top5'],\n",
    "        'Errors': metrics['errors']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"-\"*95)\n",
    "print(f\"{'Test Set':<20} {'Model':<12} {'Samples':<10} {'Accuracy':<12} {'F1-Score':<12} \"\n",
    "      f\"{'Top-3':<10} {'Top-5':<10} {'Errors':<8}\")\n",
    "print(\"-\"*95)\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"{row['Test Set']:<20} {row['Model']:<12} {row['Samples']:<10} \"\n",
    "          f\"{row['Accuracy']:.4f}       {row['F1-Score']:.4f}       \"\n",
    "          f\"{row['Top-3 Acc']:.4f}    {row['Top-5 Acc']:.4f}    {row['Errors']:<8}\")\n",
    "print(\"-\"*95)\n",
    "\n",
    "optimized_val_pred = optimized_model.predict(X_val)\n",
    "optimized_val_proba = optimized_model.predict_proba(X_val)\n",
    "optimized_clean = compute_metrics(y_val, optimized_val_pred, optimized_val_proba, label_encoder)\n",
    "optimized_noisy_pred = optimized_model.predict(X_test_noisy)\n",
    "optimized_noisy_proba = optimized_model.predict_proba(X_test_noisy)\n",
    "optimized_noisy = compute_metrics(y_test_noisy, optimized_noisy_pred, optimized_noisy_proba, label_encoder)\n",
    "\n",
    "accuracy_drop = (optimized_clean['accuracy'] - optimized_noisy['accuracy']) * 100\n",
    "f1_drop = (optimized_clean['f1'] - optimized_noisy['f1']) * 100\n",
    "print(f\"Accuracy drop from clean to noisy: {accuracy_drop:.2f}%\")\n",
    "print(f\"F1-score drop from clean to noisy: {f1_drop:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf538b26-38b3-4acf-989c-52fd9c88aa26",
   "metadata": {},
   "source": [
    "### Interactive Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c98c1012-dcb1-4eb5-a992-b98c3ec51571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def normalize_symptom(symptom_input):\n",
    "    \"\"\"\n",
    "    Normalize user input to match dataset symptom format.\n",
    "    Handles: spaces, underscores, case, extra whitespace, typos\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    normalized = symptom_input.lower().strip()\n",
    "    \n",
    "    # Replace multiple spaces with single space\n",
    "    normalized = re.sub(r'\\s+', ' ', normalized)\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    normalized = normalized.replace(' ', '_')\n",
    "    \n",
    "    # Remove any leading/trailing underscores\n",
    "    normalized = normalized.strip('_')\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def find_best_match(user_symptom, symptom_list, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Find best matching symptom from the vocabulary.\n",
    "    Uses fuzzy matching to handle typos and variations.\n",
    "    \n",
    "    Args:\n",
    "        user_symptom: User's input symptom\n",
    "        symptom_list: List of valid symptoms\n",
    "        threshold: Similarity threshold (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (matched_symptom, confidence_score) or (None, 0)\n",
    "    \"\"\"\n",
    "    # First, try exact match\n",
    "    normalized = normalize_symptom(user_symptom)\n",
    "    if normalized in symptom_list:\n",
    "        return (normalized, 1.0)\n",
    "    \n",
    "    # Try fuzzy matching\n",
    "    matches = get_close_matches(normalized, symptom_list, n=1, cutoff=threshold)\n",
    "    if matches:\n",
    "        return (matches[0], 0.8)  # Return with 0.8 confidence for fuzzy match\n",
    "    \n",
    "    return (None, 0.0)\n",
    "\n",
    "def get_symptom_suggestions(partial_input, symptom_list, n=5):\n",
    "    \"\"\"Get symptom suggestions based on partial input.\"\"\"\n",
    "    normalized = normalize_symptom(partial_input)\n",
    "    \n",
    "    # Find symptoms that start with the input\n",
    "    starts_with = [s for s in symptom_list if s.startswith(normalized)]\n",
    "    \n",
    "    # If not enough, use fuzzy matching\n",
    "    if len(starts_with) < n:\n",
    "        fuzzy_matches = get_close_matches(normalized, symptom_list, n=n, cutoff=0.4)\n",
    "        starts_with.extend([s for s in fuzzy_matches if s not in starts_with])\n",
    "    \n",
    "    return starts_with[:n]\n",
    "\n",
    "# Prediction function\n",
    "def predict_disease(symptoms_input, model, symptom_to_index, label_encoder, \n",
    "                   symptom_list, top_k=5, show_confidence=True):\n",
    "\n",
    "    # Normalize and match symptoms\n",
    "    matched_symptoms = []\n",
    "    unmatched_symptoms = []\n",
    "    fuzzy_matches = []\n",
    "    \n",
    "    for symptom in symptoms_input:\n",
    "        matched, confidence = find_best_match(symptom, symptom_list)\n",
    "        \n",
    "        if matched:\n",
    "            matched_symptoms.append(matched)\n",
    "            if confidence < 1.0:\n",
    "                fuzzy_matches.append({\n",
    "                    'input': symptom,\n",
    "                    'matched': matched,\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "        else:\n",
    "            unmatched_symptoms.append(symptom)\n",
    "    \n",
    "    # Create encoding\n",
    "    encoding = np.zeros(len(symptom_to_index))\n",
    "    for symptom in matched_symptoms:\n",
    "        if symptom in symptom_to_index:\n",
    "            encoding[symptom_to_index[symptom]] = 1\n",
    "    \n",
    "    # Make prediction\n",
    "    encoding_2d = encoding.reshape(1, -1)\n",
    "    probabilities = model.predict_proba(encoding_2d)[0]\n",
    "    \n",
    "    # Get top k predictions\n",
    "    top_k_indices = np.argsort(probabilities)[::-1][:top_k]\n",
    "    \n",
    "    predictions = []\n",
    "    for rank, idx in enumerate(top_k_indices, 1):\n",
    "        predictions.append({\n",
    "            'rank': rank,\n",
    "            'disease': label_encoder.classes_[idx],\n",
    "            'probability': probabilities[idx]\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'matched_symptoms': matched_symptoms,\n",
    "        'unmatched_symptoms': unmatched_symptoms,\n",
    "        'fuzzy_matches': fuzzy_matches,\n",
    "        'total_symptoms': len(matched_symptoms)\n",
    "    }\n",
    "\n",
    "\n",
    "def display_predictions(result):\n",
    "    \"\"\"Display prediction results in a formatted way.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DIAGNOSIS RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Show matched symptoms\n",
    "    print(f\"\\n✓ Recognized Symptoms ({result['total_symptoms']}):\")\n",
    "    for i, symptom in enumerate(result['matched_symptoms'], 1):\n",
    "        print(f\"  {i}. {symptom}\")\n",
    "    \n",
    "    # Show fuzzy matches if any\n",
    "    if result['fuzzy_matches']:\n",
    "        print(f\"\\n⚠ Approximate Matches (please verify):\")\n",
    "        for match in result['fuzzy_matches']:\n",
    "            print(f\"  • '{match['input']}' matched to '{match['matched']}' (confidence: {match['confidence']*100:.0f}%)\")\n",
    "    \n",
    "    # Show unmatched symptoms if any\n",
    "    if result['unmatched_symptoms']:\n",
    "        print(f\"\\n✗ Unrecognized Symptoms:\")\n",
    "        for symptom in result['unmatched_symptoms']:\n",
    "            print(f\"  • {symptom}\")\n",
    "            # Show suggestions\n",
    "            suggestions = get_symptom_suggestions(symptom, symptom_list, n=3)\n",
    "            if suggestions:\n",
    "                print(f\"    Did you mean: {', '.join(suggestions)}?\")\n",
    "    \n",
    "    # Show predictions\n",
    "    print(f\"\\n\" + \"-\"*80)\n",
    "    print(\"TOP {0} PREDICTED DISEASES:\".format(len(result['predictions'])))\n",
    "    print(\"-\"*80)\n",
    "    print(f\"{'Rank':<6} {'Disease':<45} {'Probability':<15}\")\n",
    "    print(\"-\"*80)\n",
    "        \n",
    "    for pred in result['predictions']:        \n",
    "        print(f\"{pred['rank']:<6} {pred['disease']:<45} {pred['probability']*100:>6.5f}%\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Clinical advice\n",
    "    print(\"\\n⚠ IMPORTANT MEDICAL DISCLAIMER:\")\n",
    "    print(\"This is an AI prediction system for educational purposes only.\")\n",
    "    print(\"Always consult qualified healthcare professionals for medical diagnosis.\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a0a070de-592e-4746-ad7e-aca5379d4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interactive_prediction():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DISEASE PREDICTION - INTERACTIVE SESSION\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Enter symptoms separated by commas. Type 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter symptoms separated by commas. Type 'quit' to exit.: \").strip()\n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"\\nThank you for using the Disease Prediction System!\")\n",
    "            break\n",
    "\n",
    "        symptoms_input = [s.strip() for s in user_input.split(\",\") if s.strip()]\n",
    "        if not symptoms_input:\n",
    "            print(\"⚠ Please enter at least one symptom.\")\n",
    "            continue\n",
    "\n",
    "        result = predict_disease(\n",
    "            symptoms_input=symptoms_input,\n",
    "            model=optimized_model, \n",
    "            symptom_to_index=symptom_to_index,\n",
    "            label_encoder=label_encoder,\n",
    "            symptom_list=symptom_list,\n",
    "            top_k=5\n",
    "        )\n",
    "\n",
    "        display_predictions(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6b44434-073c-42bc-a52b-e389c6bfdce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DISEASE PREDICTION - INTERACTIVE SESSION\n",
      "============================================================\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:  high fever, patches in throat, extra marital contacts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Recognized Symptoms (3):\n",
      "  1. high_fever\n",
      "  2. patches_in_throat\n",
      "  3. extra_marital_contacts\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOP 5 PREDICTED DISEASES:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Disease                                       Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      AIDS                                          2.44891%\n",
      "2      Gastroenteritis                               2.44353%\n",
      "3      Heart attack                                  2.44326%\n",
      "4      Hepatitis C                                   2.44167%\n",
      "5      Acne                                          2.44150%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "⚠ IMPORTANT MEDICAL DISCLAIMER:\n",
      "This is an AI prediction system for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical diagnosis.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:  vomiting, headache, weakness of one body side \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Recognized Symptoms (3):\n",
      "  1. vomiting\n",
      "  2. headache\n",
      "  3. weakness_of_one_body_side\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOP 5 PREDICTED DISEASES:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Disease                                       Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Paralysis (brain hemorrhage)                  2.44862%\n",
      "2      Gastroenteritis                               2.44353%\n",
      "3      Heart attack                                  2.44326%\n",
      "4      Hepatitis C                                   2.44245%\n",
      "5      Chronic cholestasis                           2.44173%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "⚠ IMPORTANT MEDICAL DISCLAIMER:\n",
      "This is an AI prediction system for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical diagnosis.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:  excessive hunger, stiff neck, depression, irritability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Recognized Symptoms (4):\n",
      "  1. excessive_hunger\n",
      "  2. stiff_neck\n",
      "  3. depression\n",
      "  4. irritability\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOP 5 PREDICTED DISEASES:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Disease                                       Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Gastroenteritis                               2.44353%\n",
      "2      Heart attack                                  2.44326%\n",
      "3      Chronic cholestasis                           2.44249%\n",
      "4      Hepatitis C                                   2.44245%\n",
      "5      Acne                                          2.44241%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "⚠ IMPORTANT MEDICAL DISCLAIMER:\n",
      "This is an AI prediction system for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical diagnosis.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:  indigestion, headache, blurred and distorted vision, excessive hunger, stiff neck, depression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Recognized Symptoms (6):\n",
      "  1. indigestion\n",
      "  2. headache\n",
      "  3. blurred_and_distorted_vision\n",
      "  4. excessive_hunger\n",
      "  5. stiff_neck\n",
      "  6. depression\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOP 5 PREDICTED DISEASES:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Disease                                       Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Migraine                                      2.44583%\n",
      "2      Gastroenteritis                               2.44353%\n",
      "3      Chronic cholestasis                           2.44249%\n",
      "4      Heart attack                                  2.44249%\n",
      "5      Hepatitis C                                   2.44245%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "⚠ IMPORTANT MEDICAL DISCLAIMER:\n",
      "This is an AI prediction system for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical diagnosis.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:  joint pain, neck pain, knee pain, hip joint pain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Recognized Symptoms (4):\n",
      "  1. joint_pain\n",
      "  2. neck_pain\n",
      "  3. knee_pain\n",
      "  4. hip_joint_pain\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOP 5 PREDICTED DISEASES:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Disease                                       Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Osteoarthristis                               2.44713%\n",
      "2      Gastroenteritis                               2.44353%\n",
      "3      Chronic cholestasis                           2.44252%\n",
      "4      Hepatitis C                                   2.44245%\n",
      "5      Heart attack                                  2.44145%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "⚠ IMPORTANT MEDICAL DISCLAIMER:\n",
      "This is an AI prediction system for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical diagnosis.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:   joint pain, neck pain, knee pain, hip joint pain, swelling joints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIAGNOSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "✓ Recognized Symptoms (5):\n",
      "  1. joint_pain\n",
      "  2. neck_pain\n",
      "  3. knee_pain\n",
      "  4. hip_joint_pain\n",
      "  5. swelling_joints\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TOP 5 PREDICTED DISEASES:\n",
      "--------------------------------------------------------------------------------\n",
      "Rank   Disease                                       Probability    \n",
      "--------------------------------------------------------------------------------\n",
      "1      Osteoarthristis                               2.45053%\n",
      "2      Gastroenteritis                               2.44353%\n",
      "3      Chronic cholestasis                           2.44252%\n",
      "4      Hepatitis C                                   2.44082%\n",
      "5      Heart attack                                  2.44061%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "⚠ IMPORTANT MEDICAL DISCLAIMER:\n",
      "This is an AI prediction system for educational purposes only.\n",
      "Always consult qualified healthcare professionals for medical diagnosis.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter symptoms separated by commas. Type 'quit' to exit.:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for using the Disease Prediction System!\n"
     ]
    }
   ],
   "source": [
    "# To start the interactive session, call:\n",
    "run_interactive_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d0f26-285f-4eab-a211-d14ecbbdf3e7",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The optimized AdaBoost model showed excellent performance on clean and moderately noisy test data, validating its robustness and potential for clinical support. However, accuracy dropped when dealing with blended or highly ambiguous symptom cases, and the interactive system may not always produce clinically reliable predictions for complex, real-world scenarios.\n",
    "\n",
    "Model strengths and limitations:\n",
    "The model is highly effective when enough clear and relevant symptoms are provided, achieving high accuracy and strong Top-K results. Still, its performance decreases for patient cases with overlapping or incomplete symptom profiles. Like many machine learning models in health, its accuracy is also constrained by data quality and the diversity of symptoms covered in the dataset.\n",
    "\n",
    "Impact of noise:\n",
    "The optimized system remains robust to moderate noise (extra or missing symptoms), but accuracy and confidence decline when symptom overlap increases or information is sparse. This reflects real-world situations where diagnoses are often uncertain.\n",
    "\n",
    "Real-world considerations:\n",
    "For best results, users should provide as many accurate and relevant symptoms as possible, as the model’s confidence and the chance of correct prediction both increase with richer input. In practice, this system is most valuable as a decision support tool—offering likely diagnoses for clinical review, rather than making definitive standalone predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
