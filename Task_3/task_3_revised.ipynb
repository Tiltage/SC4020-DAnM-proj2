{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa90994b-a19f-4cd6-9932-52664c4de4d0",
   "metadata": {},
   "source": [
    "# Task 3 Disease Prediction System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8e473-351f-4258-a9a1-c7619df65d27",
   "metadata": {},
   "source": [
    "### Problem Definition\n",
    "- Healthcare application context\n",
    "- Problem statement: Multi-symptom disease prediction\n",
    "- Dataset overview and project objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a55336-cc81-4985-b17b-e3527f786db7",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "- Load dataset and display basic info\n",
    "- Disease distribution analysis\n",
    "- Symptom analysis and frequency\n",
    "- Visualisations if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc9a746e-d183-4c5c-b04f-b07d428af9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    top_k_accuracy_score\n",
    ")\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a88daca2-ee19-4888-a4a0-1374eacc78a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4920, 18)\n",
      "Number of samples: 4920\n",
      "Number of columns: 18\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/kendr/Downloads/archive/dataset.csv\")\n",
    "\n",
    "# Dataset Overview\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cf24592-d32e-4c54-9de9-9d7eb274a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symptoms per disease statistics:\n",
      "count    4920.000000\n",
      "mean        7.448780\n",
      "std         3.592166\n",
      "min         3.000000\n",
      "25%         5.000000\n",
      "50%         6.000000\n",
      "75%        10.000000\n",
      "max        17.000000\n",
      "Name: Symptom_Count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Symptom Analysis\n",
    "# Your analysis code with the FIX:\n",
    "symptom_cols = [col for col in df.columns if col.startswith('Symptom_')]\n",
    "\n",
    "# Count non-null symptoms per disease (row-wise)\n",
    "df['Symptom_Count'] = df[symptom_cols].notna().sum(axis=1)\n",
    "\n",
    "print(\"Symptoms per disease statistics:\")\n",
    "print(df['Symptom_Count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "127a4560-8b56-4ca1-8baf-e956fe22052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symptoms in dataset: 131\n",
      "\n",
      "Top 20 most common symptoms:\n",
      "  fatigue: 1932\n",
      "  vomiting: 1914\n",
      "  high_fever: 1362\n",
      "  loss_of_appetite: 1152\n",
      "  nausea: 1146\n",
      "  headache: 1134\n",
      "  abdominal_pain: 1032\n",
      "  yellowish_skin: 912\n",
      "  yellowing_of_eyes: 816\n",
      "  chills: 798\n",
      "  skin_rash: 786\n",
      "  malaise: 702\n",
      "  chest_pain: 696\n",
      "  joint_pain: 684\n",
      "  itching: 678\n",
      "  sweating: 678\n",
      "  dark_urine: 570\n",
      "  cough: 564\n",
      "  diarrhoea: 564\n",
      "  irritability: 474\n"
     ]
    }
   ],
   "source": [
    "# Collect all symptoms (flatten the symptom columns)\n",
    "all_symptoms = []\n",
    "for col in symptom_cols:\n",
    "    symptoms = df[col].dropna().astype(str).str.strip()\n",
    "    all_symptoms.extend(symptoms.tolist())\n",
    "\n",
    "# Filter out \"nan\" strings\n",
    "all_symptoms = [symptom for symptom in all_symptoms if symptom.lower() != 'nan']\n",
    "\n",
    "# Count symptom frequencies\n",
    "symptom_counter = Counter(all_symptoms)\n",
    "total_unique_symptoms = len(symptom_counter)\n",
    "\n",
    "print(f\"Total unique symptoms in dataset: {total_unique_symptoms}\")\n",
    "print(\"\\nTop 20 most common symptoms:\")\n",
    "for symptom, count in symptom_counter.most_common(20):\n",
    "    print(f\"  {symptom}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb7f679-1052-436b-a3d5-a8e4eef2d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of symptoms appearing in multiple diseases: 51\n",
      "\n",
      "Top 15 symptoms by number of associated diseases:\n",
      "  vomiting: appears in 17 different diseases\n",
      "  fatigue: appears in 17 different diseases\n",
      "  high_fever: appears in 12 different diseases\n",
      "  headache: appears in 10 different diseases\n",
      "  loss_of_appetite: appears in 10 different diseases\n",
      "  nausea: appears in 10 different diseases\n",
      "  abdominal_pain: appears in 9 different diseases\n",
      "  yellowish_skin: appears in 8 different diseases\n",
      "  skin_rash: appears in 7 different diseases\n",
      "  chills: appears in 7 different diseases\n",
      "  yellowing_of_eyes: appears in 7 different diseases\n",
      "  itching: appears in 6 different diseases\n",
      "  chest_pain: appears in 6 different diseases\n",
      "  joint_pain: appears in 6 different diseases\n",
      "  sweating: appears in 6 different diseases\n"
     ]
    }
   ],
   "source": [
    "# For each symptom, count how many different diseases it appears in\n",
    "symptom_disease_map = {}\n",
    "for symptom in symptom_counter.keys():\n",
    "    diseases_with_symptom = set()\n",
    "    for col in symptom_cols:\n",
    "        diseases = df[df[col].str.strip() == symptom]['Disease'].unique()\n",
    "        diseases_with_symptom.update(diseases)\n",
    "    symptom_disease_map[symptom] = len(diseases_with_symptom)\n",
    "\n",
    "# Find symptoms that appear in multiple diseases\n",
    "multi_disease_symptoms = {k: v for k, v in symptom_disease_map.items() if v > 1}\n",
    "print(f\"\\nNumber of symptoms appearing in multiple diseases: {len(multi_disease_symptoms)}\")\n",
    "\n",
    "# Top symptoms by disease diversity\n",
    "sorted_symptoms = sorted(symptom_disease_map.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 15 symptoms by number of associated diseases:\")\n",
    "for symptom, disease_count in sorted_symptoms[:15]:\n",
    "    print(f\"  {symptom}: appears in {disease_count} different diseases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3050045d-fa0d-462b-87fa-5ea76f187c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Insights:\n",
      "  • Total diseases: 41\n",
      "  • Total unique symptoms: 131\n",
      "  • Average symptoms per disease entry: 7.45\n",
      "  • Symptoms appearing in multiple diseases: 51\n"
     ]
    }
   ],
   "source": [
    "print(\"Key Insights:\")\n",
    "print(f\"  • Total diseases: {df['Disease'].nunique()}\")\n",
    "print(f\"  • Total unique symptoms: {total_unique_symptoms}\")\n",
    "print(f\"  • Average symptoms per disease entry: {df['Symptom_Count'].mean():.2f}\")\n",
    "print(f\"  • Symptoms appearing in multiple diseases: {len(multi_disease_symptoms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fb090-9544-46e9-a239-58e91422ff9a",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Handle missing values\n",
    "- Feature engineering\n",
    "- Create feature matrix (X) and target labels (Y)\n",
    "- Train-test validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "056e7dee-aad6-45cb-b425-b5f26b6f1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Whitespace removed from all entries.\n",
      "Sample cleaned data:\n",
      "            Disease  Symptom_1             Symptom_2             Symptom_3\n",
      "0  Fungal infection    itching             skin_rash  nodal_skin_eruptions\n",
      "1  Fungal infection  skin_rash  nodal_skin_eruptions   dischromic _patches\n",
      "2  Fungal infection    itching  nodal_skin_eruptions   dischromic _patches\n",
      "3  Fungal infection    itching             skin_rash   dischromic _patches\n",
      "4  Fungal infection    itching             skin_rash  nodal_skin_eruptions\n",
      "\n",
      "'nan' strings remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "# Strip whitespace from all symptom entries (handle both string and empty)\n",
    "for col in symptom_cols:\n",
    "    df_processed[col] = df_processed[col].astype(str).str.strip()\n",
    "    # Replace 'nan' strings with empty strings (from previous astype conversion)\n",
    "    df_processed[col] = df_processed[col].replace('nan', '')\n",
    "\n",
    "# Strip whitespace from disease names\n",
    "df_processed['Disease'] = df_processed['Disease'].str.strip()\n",
    "\n",
    "print(\"\\nWhitespace removed from all entries.\")\n",
    "print(f\"Sample cleaned data:\")\n",
    "print(df_processed[['Disease'] + symptom_cols[:3]].head())\n",
    "\n",
    "# Verify no 'nan' strings remain\n",
    "nan_strings = (df_processed[symptom_cols] == 'nan').sum().sum()\n",
    "print(f\"\\n'nan' strings remaining: {nan_strings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f1ba2c9-3c6a-4588-923f-26f8603ddae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique symptoms: 131\n",
      "First 10 symptoms in vocabulary: ['abdominal_pain', 'abnormal_menstruation', 'acidity', 'acute_liver_failure', 'altered_sensorium', 'anxiety', 'back_pain', 'belly_pain', 'blackheads', 'bladder_discomfort']\n"
     ]
    }
   ],
   "source": [
    "# Collect all unique symptoms (excluding empty strings)\n",
    "all_symptoms = set()\n",
    "for col in symptom_cols:\n",
    "    symptoms = df_processed[col][df_processed[col] != ''].unique()\n",
    "    all_symptoms.update(symptoms)\n",
    "\n",
    "# Convert to sorted list for consistent indexing\n",
    "symptom_list = sorted(list(all_symptoms))\n",
    "symptom_to_index = {symptom: idx for idx, symptom in enumerate(symptom_list)}\n",
    "\n",
    "print(f\"Total unique symptoms: {len(symptom_list)}\")\n",
    "print(f\"First 10 symptoms in vocabulary: {symptom_list[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05274b45-adb1-433f-8baa-eb617600a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_hot_encoding(row, symptom_to_index, symptom_cols):\n",
    "    \"\"\"\n",
    "    Create a multi-hot encoded vector for a disease entry.\n",
    "    Each symptom present is marked as 1, absent as 0.\n",
    "    \"\"\"\n",
    "    encoding = np.zeros(len(symptom_to_index))\n",
    "    \n",
    "    for col in symptom_cols:\n",
    "        symptom = row[col]\n",
    "        if symptom != '' and symptom in symptom_to_index:\n",
    "            encoding[symptom_to_index[symptom]] = 1\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "954b5a75-b987-44e0-b413-8b73d472becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (4920, 131)\n",
      "Feature matrix dimensions: 4920 samples × 131 features\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "X = np.array([create_multi_hot_encoding(row, symptom_to_index, symptom_cols) \n",
    "              for _, row in df_processed.iterrows()])\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Feature matrix dimensions: {X.shape[0]} samples × {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "018d4b2a-5ad6-4692-a297-623d34a2c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique disease classes: 41\n",
      "\n",
      "Disease classes (first 10): ['(vertigo) Paroymsal  Positional Vertigo', 'AIDS', 'Acne', 'Alcoholic hepatitis', 'Allergy', 'Arthritis', 'Bronchial Asthma', 'Cervical spondylosis', 'Chicken pox', 'Chronic cholestasis']\n",
      "\n",
      "Sample disease mapping:\n",
      "  0: (vertigo) Paroymsal  Positional Vertigo\n",
      "  1: AIDS\n",
      "  2: Acne\n",
      "  3: Alcoholic hepatitis\n",
      "  4: Allergy\n",
      "  5: Arthritis\n",
      "  6: Bronchial Asthma\n",
      "  7: Cervical spondylosis\n",
      "  8: Chicken pox\n",
      "  9: Chronic cholestasis\n"
     ]
    }
   ],
   "source": [
    "# Encode disease labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_processed['Disease'])\n",
    "\n",
    "print(f\"Number of unique disease classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"\\nDisease classes (first 10): {list(label_encoder.classes_[:10])}\")\n",
    "\n",
    "# Create disease mapping for reference\n",
    "disease_mapping = {idx: disease for idx, disease in enumerate(label_encoder.classes_)}\n",
    "reverse_disease_mapping = {disease: idx for idx, disease in enumerate(label_encoder.classes_)}\n",
    "\n",
    "print(f\"\\nSample disease mapping:\")\n",
    "for i in range(min(10, len(disease_mapping))):\n",
    "    print(f\"  {i}: {disease_mapping[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45194c35-73a2-4abb-b2e2-51d614b8887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3936 samples (80.0%)\n",
      "Validation set size: 984 samples (20.0%)\n",
      "\n",
      "Training set shape: (3936, 131)\n",
      "Validation set shape: (984, 131)\n"
     ]
    }
   ],
   "source": [
    "# Split data - 80% train, 20% validation\n",
    "# Using stratify to maintain disease distribution\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5289380-0b2a-4b12-98ac-f62be0752a19",
   "metadata": {},
   "source": [
    "### Base Model Construction\n",
    "- Explain AdaBoost algorithm choice\n",
    "- Build baseline AdaBoost with default parameters\n",
    "- Establish baseline performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f44fb2-dd80-4377-a2df-93f7a810d948",
   "metadata": {},
   "source": [
    "#### Why AdaBoost? (TO EDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ffe0b3a-d1ee-4395-ae39-af6bc60b90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Baseline AdaBoost model\n",
    "base_adaboost = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945013bc-7ada-4179-961f-e6e7b8ee8156",
   "metadata": {},
   "source": [
    "### Model Training & Evaluation\n",
    "- Train base model on training set\n",
    "- Evaluate on validation set using:\n",
    "    Accuracy, Precision, Recall, F1-score, Confusion matrix, Top-K accuracy\n",
    "- Analyze results and error patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "941070f6-68e2-468c-99d5-26f5d1872153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.92 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model and measure time\n",
    "start_time = time.time()\n",
    "base_adaboost.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2be93f07-a7f5-4fff-ba85-97cc72d81254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training predictions generated\n",
      "✓ Validation predictions generated in 0.0686 seconds\n",
      "  Average time per prediction: 0.07 ms\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "y_train_pred = base_adaboost.predict(X_train)\n",
    "y_train_proba = base_adaboost.predict_proba(X_train)\n",
    "\n",
    "# Predictions on validation set\n",
    "start_time = time.time()\n",
    "y_val_pred = base_adaboost.predict(X_val)\n",
    "y_val_proba = base_adaboost.predict_proba(X_val)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Training predictions generated\")\n",
    "print(f\"✓ Validation predictions generated in {inference_time:.4f} seconds\")\n",
    "print(f\"  Average time per prediction: {(inference_time/len(X_val))*1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "337a20e5-7cff-4900-8273-3e43b1a7fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Metric               Training Set         Validation Set       Difference          \n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy               0.9652 (96.52%)     0.9563 (95.63%)     0.0089\n",
      "Precision              0.9845 (98.45%)     0.9843 (98.43%)     0.0001\n",
      "Recall                 0.9652 (96.52%)     0.9563 (95.63%)     0.0089\n",
      "F1-Score               0.9708 (97.08%)     0.9644 (96.44%)     0.0064\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training set metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Validation set metrics\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_precision = precision_score(y_val, y_val_pred, average='weighted', zero_division=0)\n",
    "val_recall = recall_score(y_val, y_val_pred, average='weighted', zero_division=0)\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Display results in a table\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"{'Metric':<20} {'Training Set':<20} {'Validation Set':<20} {'Difference':<20}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Accuracy':<20} {train_accuracy:>8.4f} ({train_accuracy*100:>5.2f}%)   {val_accuracy:>8.4f} ({val_accuracy*100:>5.2f}%)   {abs(train_accuracy-val_accuracy):>8.4f}\")\n",
    "print(f\"{'Precision':<20} {train_precision:>8.4f} ({train_precision*100:>5.2f}%)   {val_precision:>8.4f} ({val_precision*100:>5.2f}%)   {abs(train_precision-val_precision):>8.4f}\")\n",
    "print(f\"{'Recall':<20} {train_recall:>8.4f} ({train_recall*100:>5.2f}%)   {val_recall:>8.4f} ({val_recall*100:>5.2f}%)   {abs(train_recall-val_recall):>8.4f}\")\n",
    "print(f\"{'F1-Score':<20} {train_f1:>8.4f} ({train_f1*100:>5.2f}%)   {val_f1:>8.4f} ({val_f1*100:>5.2f}%)   {abs(train_f1-val_f1):>8.4f}\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fdd3ada2-f05f-40a9-9bab-7b2747bca9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Gap:        0.0089\n",
      "Model generalizes well (gap < 5%)\n"
     ]
    }
   ],
   "source": [
    "# Check for overfitting\n",
    "accuracy_gap = train_accuracy - val_accuracy\n",
    "\n",
    "print(f\"Accuracy Gap:        {accuracy_gap:.4f}\")\n",
    "\n",
    "if accuracy_gap < 0.05:\n",
    "    print(\"Model generalizes well (gap < 5%)\")\n",
    "elif accuracy_gap < 0.10:\n",
    "    print(\"Slight overfitting detected (gap 5-10%)\")\n",
    "else:\n",
    "    print(\"Significant overfitting (gap > 10%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "07bb7a0d-6be0-4a51-8a79-672c896812a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Top-K           Training Set              Validation Set            Improvement    \n",
      "--------------------------------------------------------------------------------\n",
      "Top-1             0.9652 (96.52%)        0.9563 (95.63%)      + 0.00%\n",
      "Top-2             0.9970 (99.70%)        0.9939 (99.39%)      + 3.76%\n",
      "Top-3             0.9990 (99.90%)        0.9980 (99.80%)      + 4.17%\n",
      "Top-5             1.0000 (100.00%)        1.0000 (100.00%)      + 4.37%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Key Insights:\n",
      "  • Top-1 Accuracy: 95.63% (exact match)\n",
      "  • Top-3 Accuracy: 99.80% (correct diagnosis in top 3)\n",
      "  • Top-5 Accuracy: 100.00% (correct diagnosis in top 5)\n",
      "  • Considering top 3 predictions improves accuracy by 4.17%\n"
     ]
    }
   ],
   "source": [
    "# Top-K Accuracy Analysis\n",
    "# Measures if the correct disease appears in the top K predictions (ranked by confidence)\n",
    "\n",
    "# Calculate Top-K accuracies for K = 1, 2, 3, 5\n",
    "k_values = [1, 2, 3, 5]\n",
    "topk_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Training set\n",
    "    train_topk = top_k_accuracy_score(y_train, y_train_proba, k=k, labels=np.arange(len(label_encoder.classes_)))\n",
    "    # Validation set\n",
    "    val_topk = top_k_accuracy_score(y_val, y_val_proba, k=k, labels=np.arange(len(label_encoder.classes_)))\n",
    "    topk_results.append({\n",
    "        'K': k,\n",
    "        'Train': train_topk,\n",
    "        'Validation': val_topk\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"{'Top-K':<15} {'Training Set':<25} {'Validation Set':<25} {'Improvement':<15}\")\n",
    "print(\"-\"*80)\n",
    "for result in topk_results:\n",
    "    k = result['K']\n",
    "    train_acc = result['Train']\n",
    "    val_acc = result['Validation']\n",
    "    improvement = val_acc - topk_results[0]['Validation']  # vs Top-1\n",
    "    \n",
    "    print(f\"{'Top-'+str(k):<15} {train_acc:>8.4f} ({train_acc*100:>5.2f}%)      {val_acc:>8.4f} ({val_acc*100:>5.2f}%)      +{improvement*100:>5.2f}%\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"  • Top-1 Accuracy: {topk_results[0]['Validation']*100:.2f}% (exact match)\")\n",
    "print(f\"  • Top-3 Accuracy: {topk_results[2]['Validation']*100:.2f}% (correct diagnosis in top 3)\")\n",
    "print(f\"  • Top-5 Accuracy: {topk_results[3]['Validation']*100:.2f}% (correct diagnosis in top 5)\")\n",
    "improvement_top3 = (topk_results[2]['Validation'] - topk_results[0]['Validation']) * 100\n",
    "print(f\"  • Considering top 3 predictions improves accuracy by {improvement_top3:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1a93702-0615-47d4-b86b-35106a4852e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOP 10 PERFORMING DISEASES (by F1-Score) ---\n",
      "Disease                                       Precision    Recall       F1-Score     Samples \n",
      "-----------------------------------------------------------------------------------------------\n",
      "AIDS                                            1.0000       1.0000       1.0000     24      \n",
      "Acne                                            1.0000       1.0000       1.0000     24      \n",
      "Arthritis                                       1.0000       1.0000       1.0000     24      \n",
      "Common Cold                                     1.0000       1.0000       1.0000     24      \n",
      "Dengue                                          1.0000       1.0000       1.0000     24      \n",
      "Diabetes                                        1.0000       1.0000       1.0000     24      \n",
      "Dimorphic hemmorhoids(piles)                    1.0000       1.0000       1.0000     24      \n",
      "Drug Reaction                                   1.0000       1.0000       1.0000     24      \n",
      "GERD                                            1.0000       1.0000       1.0000     24      \n",
      "Heart attack                                    1.0000       1.0000       1.0000     24      \n",
      "\n",
      "--- BOTTOM 10 DISEASES NEEDING IMPROVEMENT ---\n",
      "Disease                                       Precision    Recall       F1-Score     Samples \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Psoriasis                                       1.0000       0.9583       0.9787     24      \n",
      "Hepatitis C                                     1.0000       0.9167       0.9565     24      \n",
      "Allergy                                         1.0000       0.8750       0.9333     24      \n",
      "Bronchial Asthma                                1.0000       0.8750       0.9333     24      \n",
      "Cervical spondylosis                            1.0000       0.8750       0.9333     24      \n",
      "Fungal infection                                1.0000       0.7917       0.8837     24      \n",
      "Gastroenteritis                                 1.0000       0.7917       0.8837     24      \n",
      "Alcoholic hepatitis                             1.0000       0.7083       0.8293     24      \n",
      "Typhoid                                         1.0000       0.7083       0.8293     24      \n",
      "Chronic cholestasis                             0.3582       1.0000       0.5275     24      \n",
      "\n",
      "✓ 24/41 diseases achieved perfect F1-score (100%)\n"
     ]
    }
   ],
   "source": [
    "# Get detailed classification report\n",
    "class_report = classification_report(\n",
    "    y_val, \n",
    "    y_val_pred, \n",
    "    target_names=label_encoder.classes_,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Extract per-class metrics\n",
    "class_performance = []\n",
    "for disease, metrics in class_report.items():\n",
    "    if disease not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        class_performance.append({\n",
    "            'Disease': disease,\n",
    "            'Precision': metrics['precision'],\n",
    "            'Recall': metrics['recall'],\n",
    "            'F1-Score': metrics['f1-score'],\n",
    "            'Support': int(metrics['support'])\n",
    "        })\n",
    "\n",
    "# Sort by F1-score\n",
    "class_performance.sort(key=lambda x: x['F1-Score'], reverse=True)\n",
    "\n",
    "# Display top performers\n",
    "print(\"\\n--- TOP 10 PERFORMING DISEASES (by F1-Score) ---\")\n",
    "print(f\"{'Disease':<45} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Samples':<8}\")\n",
    "print(\"-\"*95)\n",
    "for i, perf in enumerate(class_performance[:10], 1):\n",
    "    print(f\"{perf['Disease']:<45} {perf['Precision']:>8.4f}     {perf['Recall']:>8.4f}     {perf['F1-Score']:>8.4f}     {perf['Support']:<8}\")\n",
    "\n",
    "# Display bottom performers\n",
    "print(\"\\n--- BOTTOM 10 DISEASES NEEDING IMPROVEMENT ---\")\n",
    "print(f\"{'Disease':<45} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Samples':<8}\")\n",
    "print(\"-\"*95)\n",
    "for perf in class_performance[-10:]:\n",
    "    print(f\"{perf['Disease']:<45} {perf['Precision']:>8.4f}     {perf['Recall']:>8.4f}     {perf['F1-Score']:>8.4f}     {perf['Support']:<8}\")\n",
    "\n",
    "# Count perfect predictions\n",
    "perfect_diseases = sum(1 for p in class_performance if p['F1-Score'] == 1.0)\n",
    "print(f\"\\n✓ {perfect_diseases}/{len(class_performance)} diseases achieved perfect F1-score (100%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "41835f18-5a50-48d5-bc1b-b949f33fb063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Statistics:\n",
      "  • Total Predictions: 984\n",
      "  • Correct Predictions: 941 (95.63%)\n",
      "  • Misclassifications: 43 (4.37%)\n",
      "\n",
      "--- TOP 10 MOST CONFUSED DISEASE PAIRS ---\n",
      "(True Disease → Predicted Disease: Count)\n",
      "--------------------------------------------------------------------------------\n",
      " 1. Alcoholic hepatitis                      → Chronic cholestasis                      (7 times)\n",
      " 2. Typhoid                                  → Chronic cholestasis                      (7 times)\n",
      " 3. Fungal infection                         → Chronic cholestasis                      (5 times)\n",
      " 4. Gastroenteritis                          → Chronic cholestasis                      (5 times)\n",
      " 5. Allergy                                  → Chronic cholestasis                      (3 times)\n",
      " 6. Bronchial Asthma                         → Chronic cholestasis                      (3 times)\n",
      " 7. Cervical spondylosis                     → Chronic cholestasis                      (3 times)\n",
      " 8. Hepatitis C                              → Chronic cholestasis                      (2 times)\n",
      " 9. (vertigo) Paroymsal  Positional Vertigo  → Chronic cholestasis                      (1 times)\n",
      "10. Chicken pox                              → Chronic cholestasis                      (1 times)\n",
      "\n",
      "--- DISEASES WITH MOST MISCLASSIFICATIONS ---\n",
      "\n",
      "Disease                                       False Neg    False Pos    Total     \n",
      "--------------------------------------------------------------------------------\n",
      "Chronic cholestasis                           0            43           43        \n",
      "Alcoholic hepatitis                           7            0            7         \n",
      "Typhoid                                       7            0            7         \n",
      "Fungal infection                              5            0            5         \n",
      "Gastroenteritis                               5            0            5         \n",
      "Allergy                                       3            0            3         \n",
      "Bronchial Asthma                              3            0            3         \n",
      "Cervical spondylosis                          3            0            3         \n",
      "Hepatitis C                                   2            0            2         \n",
      "(vertigo) Paroymsal  Positional Vertigo       1            0            1         \n"
     ]
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Calculate key metrics from confusion matrix\n",
    "correct_predictions = np.trace(cm)\n",
    "total_predictions = np.sum(cm)\n",
    "misclassifications = total_predictions - correct_predictions\n",
    "\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"  • Total Predictions: {total_predictions}\")\n",
    "print(f\"  • Correct Predictions: {correct_predictions} ({correct_predictions/total_predictions*100:.2f}%)\")\n",
    "print(f\"  • Misclassifications: {misclassifications} ({misclassifications/total_predictions*100:.2f}%)\")\n",
    "\n",
    "# Find most confused disease pairs\n",
    "print(\"\\n--- TOP 10 MOST CONFUSED DISEASE PAIRS ---\")\n",
    "print(\"(True Disease → Predicted Disease: Count)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "confusion_pairs = []\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        if i != j and cm[i][j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'True': label_encoder.classes_[i],\n",
    "                'Predicted': label_encoder.classes_[j],\n",
    "                'Count': cm[i][j]\n",
    "            })\n",
    "\n",
    "confusion_pairs.sort(key=lambda x: x['Count'], reverse=True)\n",
    "\n",
    "for idx, pair in enumerate(confusion_pairs[:10], 1):\n",
    "    print(f\"{idx:>2}. {pair['True']:<40} → {pair['Predicted']:<40} ({pair['Count']} times)\")\n",
    "\n",
    "# Analyze which diseases are most problematic\n",
    "print(\"\\n--- DISEASES WITH MOST MISCLASSIFICATIONS ---\")\n",
    "disease_errors = []\n",
    "for i in range(len(cm)):\n",
    "    # Row sum minus diagonal = total errors for this disease (false negatives)\n",
    "    false_negatives = np.sum(cm[i, :]) - cm[i, i]\n",
    "    # Column sum minus diagonal = times other diseases were classified as this (false positives)\n",
    "    false_positives = np.sum(cm[:, i]) - cm[i, i]\n",
    "    total_errors = false_negatives + false_positives\n",
    "    \n",
    "    if total_errors > 0:\n",
    "        disease_errors.append({\n",
    "            'Disease': label_encoder.classes_[i],\n",
    "            'False_Negatives': false_negatives,\n",
    "            'False_Positives': false_positives,\n",
    "            'Total_Errors': total_errors\n",
    "        })\n",
    "\n",
    "disease_errors.sort(key=lambda x: x['Total_Errors'], reverse=True)\n",
    "\n",
    "print(f\"\\n{'Disease':<45} {'False Neg':<12} {'False Pos':<12} {'Total':<10}\")\n",
    "print(\"-\"*80)\n",
    "for error in disease_errors[:10]:\n",
    "    print(f\"{error['Disease']:<45} {error['False_Negatives']:<12} {error['False_Positives']:<12} {error['Total_Errors']:<10}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fda1e0e-6f6d-4083-bea7-f5127624adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Problematic Disease: Chronic cholestasis\n",
      "  • Total Errors: 43\n",
      "  • False Negatives: 0 (missed diagnoses)\n",
      "  • False Positives: 43 (over-diagnosed)\n",
      "\n",
      "  This disease is most confused with:\n",
      "    ← Often receives misclassifications from: Alcoholic hepatitis (7 times)\n",
      "    ← Often receives misclassifications from: Typhoid (7 times)\n",
      "    ← Often receives misclassifications from: Fungal infection (5 times)\n",
      "    ← Often receives misclassifications from: Gastroenteritis (5 times)\n",
      "    ← Often receives misclassifications from: Allergy (3 times)\n"
     ]
    }
   ],
   "source": [
    "# Error pattern insights\n",
    "# Identify the most problematic disease\n",
    "most_confused = disease_errors[0] if disease_errors else None\n",
    "\n",
    "if most_confused:\n",
    "    problem_disease = most_confused['Disease']\n",
    "    problem_idx = np.where(label_encoder.classes_ == problem_disease)[0][0]\n",
    "    \n",
    "    print(f\"\\nMost Problematic Disease: {problem_disease}\")\n",
    "    print(f\"  • Total Errors: {most_confused['Total_Errors']}\")\n",
    "    print(f\"  • False Negatives: {most_confused['False_Negatives']} (missed diagnoses)\")\n",
    "    print(f\"  • False Positives: {most_confused['False_Positives']} (over-diagnosed)\")\n",
    "    \n",
    "    # Find what it's confused with\n",
    "    print(f\"\\n  This disease is most confused with:\")\n",
    "    related_confusions = [p for p in confusion_pairs \n",
    "                         if p['True'] == problem_disease or p['Predicted'] == problem_disease][:5]\n",
    "    for conf in related_confusions:\n",
    "        if conf['True'] == problem_disease:\n",
    "            print(f\"    → Often misclassified as: {conf['Predicted']} ({conf['Count']} times)\")\n",
    "        else:\n",
    "            print(f\"    ← Often receives misclassifications from: {conf['True']} ({conf['Count']} times)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cae88f76-7046-4aaa-9a21-f17a0c943849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Example 1: True Disease = Allergy\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Confidence     \n",
      "--------------------------------------------------------------------------------\n",
      "1      Allergy                                         2.44%  ✓ CORRECT\n",
      "2      Chronic cholestasis                             2.44%  \n",
      "3      Hepatitis D                                     2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 2: True Disease = Varicose veins\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Confidence     \n",
      "--------------------------------------------------------------------------------\n",
      "1      Varicose veins                                  2.44%  ✓ CORRECT\n",
      "2      Hepatitis D                                     2.44%  \n",
      "3      Chronic cholestasis                             2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 3: True Disease = Psoriasis\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Confidence     \n",
      "--------------------------------------------------------------------------------\n",
      "1      Psoriasis                                       2.44%  ✓ CORRECT\n",
      "2      Hepatitis D                                     2.44%  \n",
      "3      Jaundice                                        2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 4: True Disease = Osteoarthristis\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Confidence     \n",
      "--------------------------------------------------------------------------------\n",
      "1      Osteoarthristis                                 2.45%  ✓ CORRECT\n",
      "2      Chronic cholestasis                             2.44%  \n",
      "3      Hepatitis D                                     2.44%  \n",
      "\n",
      "================================================================================\n",
      "Example 5: True Disease = Hepatitis B\n",
      "================================================================================\n",
      "Rank   Predicted Disease                             Confidence     \n",
      "--------------------------------------------------------------------------------\n",
      "1      Hepatitis B                                     2.44%  ✓ CORRECT\n",
      "2      Chronic cholestasis                             2.44%  \n",
      "3      Jaundice                                        2.44%  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample predictions\n",
    "# Select 5 random samples from validation set\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_val), size=5, replace=False)\n",
    "\n",
    "for idx, sample_idx in enumerate(sample_indices, 1):\n",
    "    true_label = y_val[sample_idx]\n",
    "    true_disease = label_encoder.classes_[true_label]\n",
    "    probabilities = y_val_proba[sample_idx]\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_k_indices = np.argsort(probabilities)[::-1][:3]\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Example {idx}: True Disease = {true_disease}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"{'Rank':<6} {'Predicted Disease':<45} {'Confidence':<15}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for rank, pred_idx in enumerate(top_k_indices, 1):\n",
    "        pred_disease = label_encoder.classes_[pred_idx]\n",
    "        confidence = probabilities[pred_idx]\n",
    "        \n",
    "        # Mark if correct\n",
    "        marker = \"✓ CORRECT\" if pred_idx == true_label else \"\"\n",
    "        print(f\"{rank:<6} {pred_disease:<45} {confidence*100:>6.2f}%  {marker}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "44eff2a7-8ccf-4bda-b161-2819df0d66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy                : 0.9563 (95.63%)\n",
      "  Validation Precision               : 0.9843\n",
      "  Validation Recall                  : 0.9563\n",
      "  Validation F1-Score                : 0.9644\n",
      "  Top-3 Accuracy                     : 0.9980 (99.80%)\n",
      "  Top-5 Accuracy                     : 1.0000 (100.00%)\n",
      "  Perfect F1-Score Diseases          : 24/41\n",
      "  Total Misclassifications           : 43/984\n",
      "  Training Time                      : 0.92 seconds\n",
      "  Inference Time (per sample)        : 0.07 ms\n"
     ]
    }
   ],
   "source": [
    "summary_table = {\n",
    "    'Metric': [\n",
    "        'Validation Accuracy',\n",
    "        'Validation Precision',\n",
    "        'Validation Recall',\n",
    "        'Validation F1-Score',\n",
    "        'Top-3 Accuracy',\n",
    "        'Top-5 Accuracy',\n",
    "        'Perfect F1-Score Diseases',\n",
    "        'Total Misclassifications',\n",
    "        'Training Time',\n",
    "        'Inference Time (per sample)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{val_accuracy:.4f} ({val_accuracy*100:.2f}%)\",\n",
    "        f\"{val_precision:.4f}\",\n",
    "        f\"{val_recall:.4f}\",\n",
    "        f\"{val_f1:.4f}\",\n",
    "        f\"{topk_results[2]['Validation']:.4f} ({topk_results[2]['Validation']*100:.2f}%)\",\n",
    "        f\"{topk_results[3]['Validation']:.4f} ({topk_results[3]['Validation']*100:.2f}%)\",\n",
    "        f\"{perfect_diseases}/{len(class_performance)}\",\n",
    "        f\"{misclassifications}/{total_predictions}\",\n",
    "        f\"{training_time:.2f} seconds\",\n",
    "        f\"{(inference_time/len(X_val))*1000:.2f} ms\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for metric, value in zip(summary_table['Metric'], summary_table['Value']):\n",
    "    print(f\"  {metric:<35}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9918b5-69a8-45f6-adb7-049218bc012c",
   "metadata": {},
   "source": [
    "### Test Set Construction with Noise\n",
    "- Explain rationale: Real-world symptoms often overlap diseases\n",
    "- Noise injection strategy: Blend symptoms from 2-3 different diseases\n",
    "- Document noise levels (e.g., 20%, 50% noisy samples)\n",
    "- Create realistic test scenarios\n",
    "- Take 1-3 diseases and blend their symptoms together and see if the predicted disease from the different Boosted models make sense. For example, if I pick Diseases A,B,C and blend 8 symptoms(A,A,A,A,A,B,C,C), I expect my model to give me a high probability to be class A over classes B and C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbe7d5-c6fd-43ff-be1c-0dcec7f11513",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "- Define parameter grid (n_estimators, learning_rate, base_estimator params)\n",
    "- GridSearchCV with cross-validation (5-fold or 10-fold)\n",
    "- Display best parameters found\n",
    "- Compare CV scores across parameter combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c635e2-b6b0-4f5b-a1f2-2532b6f27fad",
   "metadata": {},
   "source": [
    "### Final Model Evaluation\n",
    "- Retrain with best hyperparameters on full training set\n",
    "- Predict on clean validation set\n",
    "- Predict on noisy test set\n",
    "- Compare performance: clean vs. noisy data\n",
    "- Top-K predictions: Show ranked disease predictions with confidence scores\n",
    "- Case studies: Show 5-10 example predictions with interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf538b26-38b3-4acf-989c-52fd9c88aa26",
   "metadata": {},
   "source": [
    "### Interactive Demo\n",
    "- Input symptoms\n",
    "- Display top 3-5 disease predictions with probabilities\n",
    "- Shows practical applicability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d0f26-285f-4eab-a211-d14ecbbdf3e7",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- Model strengths and limitations\n",
    "- Impact of noise on predictions\n",
    "- Real world considerations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
